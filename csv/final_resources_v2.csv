ID,Name,Article / Other Name,Description,AI Life Cycle Stage,High Level Principle,Associated Principles,Task,Level of Development,Sector,Tool Type,Programming Language,DOI / URL,Year,Authors / Owners,Other Links
1,AI Commons,,,"Collection, understanding and preparation of data",Beneficence,Beneficence; Responsibility; Trust,Does not apply,"4,7",Academic; NGO; Private,Website,Does not apply,https://ai-commons.org/,2016,"Jose Ignacio Diaz, Maria Axente, Tara Chklovski, Max Cappellari, Gilles Fayad, Mathilde Forslund, Uyi Stewart, Nishan Chelvachandran, Trent McConaghy",
2,The AI-RFX Procurement Framework,,,Deployment and monitoring,Non-Maleficence,Non-Maleficence; Safety; Responsibility,Does not apply,4,Academic; Private; Public,Practical Framework,Does not apply,https://ethical.institute/rfx.html,2018,The Institute for Ethical AI & Machine Learning,https://ethical.institute/
3,Towards a Principled Approach for Engineering Privacy by Design,Towards a Principled Approach for Engineering Privacy by Design,,Businness and problem understanding,Non-Maleficence,Privacy; Non-Maleficence; Accountability; Transparency,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1007/978-3-319-67280-9_9,2017,"Majed Alshammari, Andrew Simpson ",https://sci-hub.ru/10.1007/978-3-319-67280-9_9
4,DataMin,Data Minimisation: a Language-Based Approach (Long Version),,"Collection, understanding and preparation of data",Non-Maleficence,Privacy; Security,Does not apply,"2,8",Academic,Article; Code,Python,https://doi.org/10.48550/arXiv.1611.05642,2016,"Thibaud Antignac, David Sands, Gerardo Schneider",https://arxiv.org/pdf/1801.02484v1.pdf
5,FactSheets,FactSheets: Increasing Trust in AI Services through Supplier's Declarations of Conformity,,Deployment and monitoring,Explicability,Transparency; Accountability; Traceability,Does not apply,4,Academic,Practical Framework,Does not apply,https://doi.org/10.48550/arXiv.1808.07261,2019,"Matthew Arnold, Rachel K. E. Bellamy, Michael Hind, Stephanie Houde, Sameep Mehta, Aleksandra Mojsilovic, Ravi Nair, Karthikeyan Natesan Ramamurthy, Darrell Reimer, Alexandra Olteanu, David Piorkowski, Jason Tsay, Kush R. Varshney",https://aifs360.mybluemix.net/
6,"The ""big red button"" is too late: an alternative model for the ethical evaluation of AI systems","The ""big red button"" is too late: an alternative model for the ethical evaluation of AI systems",,Deployment and monitoring,Beneficence,Auditability; Beneficence,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1007/s10676-018-9447-7,2018,"Thomas Arnold, Matthias Scheutz ","https://sci-hub.ru/10.1007/s10676-018-9447-7

https://markriedl.github.io/big-red-button/"
7,On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation,On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation,,Performance evaluation,Explicability,Explicability; Transparency,Computer Vision,3,Academic,Article; Code,Python,https://doi.org/10.1371/journal.pone.0130140,2015,"Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, Wojciech Samek ",
8,Model-Agnostic Private Learning via Stability,Model-Agnostic Private Learning via Stability,,Model setup and training,Non-Maleficence,Privacy,Binary Classification; Multi-class Classification,3,Academic,Code; Article,Unknown,https://doi.org/10.48550/arXiv.1803.05101,2018,"Raef Bassily, Om Thakkar, Abhradeep Thakurta",
9,Data Statements for NLP,Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science,,"Collection, understanding and preparation of data",Justice,Fairness; Inclusion,Natural Language Processing,4,Academic,Practical Framework,Does not apply,https://doi.org/10.1162/tacl_a_00041,2018,"Emily M. Bender, Batya Friedman",
10,Algorithmic Accountability and Public Reason,Algorithmic Accountability and Public Reason,,Businness and problem understanding,Justice,Responsibility; Accountability,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1007/s13347-017-0263-5,2018,Reuben Binns,
11,The ICO and artificial intelligence: The role of fairness in the GDPR framework,The ICO and artificial intelligence: The role of fairness in the GDPR framework,,Planning and design; Deployment and monitoring,Autonomy; Autonomy,Fairness; Privacy; Responsibility; Trust,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1016/j.clsr.2018.01.004,2018,Michael Butterworth,https://gdpr.eu/tag/gdpr/
12,Algorithmic Transparency method - Quantitative Input Influence (QII),Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems,,Performance evaluation,Explicability,Explicability; Transparency; Interpretability,Multi-class Classification,4,Academic,Article; Code,Python,https://doi.org/10.1109/SP.2016.42,2016,"Anupam Datta, Shayak Sen, Yair Zick","https://github.com/hovinh/QII

https://github.com/hovinh/IRIS_Transparency"
13,Practical verification of decision-making in agent-based autonomous systems,Practical verification of decision-making in agent-based autonomous systems,,Performance evaluation,Non-Maleficence,Autonomy; Auditability; Accountability,Does not apply,"3,4",Academic,Code; Article,Java,https://doi.org/10.1007/s10515-014-0168-9,2016,"Louise A. Dennis, Michael Fisher, Nicholas K. Lincoln, Alexei Lisitsa, Sandor M. Veres",https://github.com/mcapl/mcapl
14,Algorithmic Accountability: Journalistic Investigation of Computational Power Structures,Algorithmic Accountability: Journalistic Investigation of Computational Power Structures,,Deployment and monitoring,Justice,Transparency; Accountability,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1080/21670811.2014.976411,2015,Nicholas Diakopoulos,https://computingeverywhere.soc.northwestern.edu/wp-content/uploads/2017/07/Diakopoulos-Algorithmic-Accountability-Required.pdf
15,Principles for Accountable Algorithms and a Social Impact Statement for Algorithms,,,Businness and problem understanding; Deployment and monitoring,Justice; Non-Maleficence,Trust; Responsibility; Accountability,Does not apply,Does not apply,Academic,Principles,Does not apply,https://www.fatml.org/resources/principles-for-accountable-algorithms,2016,"Nicholas Diakopoulos, Sorelle Friedler, Marcelo Arenas, Solon Barocas, Michael Hay, Bill Howe, H. V. Jagadish, Kris Unsworth, Arnaud Sahuguet, Suresh Venkatasubramanian, Christo Wilson, Cong Yu, Bendert Zevenbergen",https://www.fatml.org/
16,Algorithm Tips,Algorithm Tips: A Resource for Algorithmic Accountability in Government,,Deployment and monitoring,Justice,Accountability,Does not apply,4,Academic,Website; Resource Compendium; Article,Does not apply,https://cj2017.northwestern.edu/documents/algorithm-cj2017-paper-13.pdf,2017,"Nicholas Diakopoulos, Daniel Trielli, Jennifer A. Stark","http://algorithmtips.org/

http://db.algorithmtips.org/db"
17,Consequence Scanning,Consequence Scanning: An agile practice for responsible innovators,,Businness and problem understanding,Beneficence,Fairness; Inclusion; Auditability,Does not apply,4,Private,Guide,Does not apply,https://doteveryone.org.uk/wp-content/uploads/2021/02/Consequence-Scanning-Agile-Event-Manual-TechTransformed-Doteveryone-2.pdf,2019,Doteveryone,https://doteveryone.org.uk/project/consequence-scanning/
18,Ellpha,,,"Deployment and monitoring; Collection, understanding and preparation of data",Justice; Justice,Inclusion; Fairness,Does not apply,4,NGO,Website,Does not apply,https://www.ellpha.com/what-is-ellpha,2018,"Brigitte Ricou-Bellan, Stephanié Creff",https://www.ellpha.com
19,TuringBox,TuringBox: An Experimental Platform for the Evaluation of AI Systems,,Deployment and monitoring,Justice,Reproducibility; Auditability,Regression; Computer Vision; Natural Language Processing,4,Academic,Code; Article,Python,https://doi.org/10.24963/ijcai.2018/851,2018,"Ziv Epstein, Blakeley H. Payne, Judy Hanwen Shen, Casey Jisoo Hong, Bjarke Felbo, Abhimanyu Dubey, Matthew Groh, Nick Obradovich, Manuel Cebrian, Iyad Rahwan","https://github.com/mitmedialab/turingbox

https://www.media.mit.edu/projects/turingbox/overview/"
20,Equity Evaluation Corpus (EEC),Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems,,"Collection, understanding and preparation of data",Justice,Fairness,Natural Language Processing,4,Academic,Dataset; Article,Does not apply,https://saifmohammad.com/WebDocs/EEC/ethics-StarSem-final_with_appendix.pdf,2018,"Svetlana Kiritchenko, Saif M. Mohammad","https://saifmohammad.com/WebPages/Biases-SA.html

https://github.com/algorithmicbiaslab/expanded-equity-corpus"
21,EthicsNet,,,"Collection, understanding and preparation of data; Performance evaluation",Beneficence; Justice,Fairness; Diversity,Does not apply,4,NGO,Website; Dataset,Does not apply,https://www.ethicsnet.org,2019,"Anish Mohammed, Remco Bloemen, Nell Watson, Emerson Lopes, Ola Orchowska, Franziska Lippoldt, Roshawn Terrell, Nikola Stojkovic, Adam Alonzi, Phaedra Mohammed",https://www.ethicsnet.org/about
22,Certifying and Removing Disparate Impact,Certifying and Removing Disparate Impact,,Performance evaluation,Justice,Fairness,Multi-class Classification,"3,5",Academic,Article; Code,Python,https://doi.org/10.1145/2783258.2783311,2015,"Michael Feldman,  Sorelle A. Friedler, John Moeller, Carlos Scheidegger, Suresh Venkatasubramanian","https://arxiv.org/abs/1412.3756

https://github.com/algofairness/BlackBoxAuditing

https://github.com/jakainic/Disparate_Impact"
23,A Confidence-Based Approach for Balancing Fairness and Accuracy,A Confidence-Based Approach for Balancing Fairness and Accuracy,,Model setup and training,Justice,Fairness,Multi-class Classification; Regression,"3,6",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1601.05764,2016,"Benjamin Fish, Jeremy Kun, Ádám D. Lelkes",https://github.com/j2kun/fkl-SDM16
24,A Survey of Value Sensitive Design Methods,A Survey of Value Sensitive Design Methods,,Planning and design,Beneficence,Responsibility,Does not apply,"3,3",Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1561/1100000015,2017,"Batya Friedman, David G. Hendry, Alan Borning",https://sci-hub.ru/10.1561/1100000015
25,Futures Wheel,,,Businness and problem understanding,Non-Maleficence,Auditability; Prevention,Does not apply,4,NGO,Practical Framework; Website,Does not apply,http://ethicskit.org/futures-wheel.html,2019,Jerome C. Glenn,https://ethicskit.org/tools.html
26,A Survey Of Methods For Explaining Black Box Models,A Survey Of Methods For Explaining Black Box Models,,Performance evaluation,Explicability,Explicability; Interpretability,Does not apply,Does not apply,Academic,Article; Resource Compendium,Does not apply,https://doi.org/10.1145/3236009,2018,"Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, Dino Pedreschi",
27,Machine Learning Interpretability (MLI) Resources,"An introduction to machine learning interpretability: an applied perspective on fairness, accountability, transparency, and explainable AI",,Model setup and training; Performance evaluation,Explicability; Explicability,Interpretability; Explicability,Multi-class Classification; Regression,4,Academic,Book; Code; Examples,Python,https://www.oreilly.com/library/view/an-introduction-to/9781492033158/,2018,"Patrick Hall, Navdeep Gill","https://h2o.ai/resources/ebook/introduction-to-machine-learning-interpretability/

https://github.com/h2oai/mli-resources

https://github.com/h2oai/mli-resources/blob/master/notebooks/mono_xgboost.ipynb

https://github.com/h2oai/mli-resources/blob/master/notebooks/pdp_ice.ipynb"
28,Hazy,,,"Collection, understanding and preparation of data",Non-Maleficence,Privacy; Security; Reliability,Does not apply,"4,8",Private,Website,Does not apply,https://hazy.com/,2017,"Harry Keen, Luke Robinson, Marisa Teh, Andrew Keen, Karl Tishler",https://hazy.com/product/why-synthetic-data
29,Ethics Cards,,,Businness and problem understanding,Beneficence,Inclusion; Responsibility,Does not apply,4,NGO,Practical Framework; Website,Does not apply,http://ethicskit.org/ethics-cards.html,2018,Philip Hesketh,https://ethicskit.org/tools.html
30,Dataset Nutrition Label,The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards,,"Collection, understanding and preparation of data",Justice,Accountability; Transparency; Auditability,Does not apply,"4,7",Academic,Practical Framework; Website; Article,Does not apply,https://doi.org/10.48550/arXiv.1805.03677,2018,"Sarah Holland, Ahmed Hosny, Sarah Newman, Joshua Joseph, Kasia Chmielinski","https://datanutrition.org/

https://ahmedhosny.github.io/datanutrition/

https://labelmaker.datanutrition.org/"
31,Anonymisation: managing data protection risk code of practice,,,"Collection, understanding and preparation of data",Justice,Privacy; Security; Safety,Does not apply,4,Public,Code of Practice,Does not apply,https://ico.org.uk/media/1061/anonymisation-code.pdf,2015,Information Commissioner's Office (ICO),https://ico.org.uk/media/about-the-ico/consultations/2619862/anonymisation-intro-and-first-chapter.pdf
32,UK GDPR Guidance and Resources,,,"Planning and design; Collection, understanding and preparation of data",Autonomy; Justice; Governance,Privacy; Security; Autonomy; Fairness,Does not apply,4,Public,Resource Compendium,Does not apply,https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/,2018,Information Commissioner's Office (ICO),
33,The Field Guide to Human-Centered Design,,,Planning and design,Beneficence,Diversity; Inclusion; Human Rights,Does not apply,4,NGO,Guide; Resource Compendium,Does not apply,https://www.designkit.org/resources/1.html,2015,IDEO Organization,"https://www.ideo.com/post/design-kit

https://www.designkit.org/

https://www.ideo.org/tools"
34,Ethically Aligned Design,White Paper - Ethically Aligned Design - A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems,,Businness and problem understanding,Beneficence,Human Rights; Well-being; Inclusion; Social Good,Does not apply,"3,6",Academic,White Paper,Does not apply,https://ieeexplore.ieee.org/document/9398613,2019,Institute of Electrical and Electronics Engineers (IEEE),https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9398613
35,How to stimulate effective public engagement on the ethics of Artificial Intelligence,,,Businness and problem understanding,Beneficence,Social Good; Inclusion; Diversity,Does not apply,Does not apply,Private,Theory Document,Does not apply,https://involve.org.uk/resources/publications/project-reports/how-stimulate-effective-public-engagement-ethics-artificial,2019,"Involve, DeepMind",https://involve.org.uk/sites/default/files/field/attachemnt/How%20to%20stimulate%20effective%20public%20debate%20on%20the%20ethics%20of%20artificial%20intelligence%20.pdf
36,Learning Representations for Counterfactual Inference,Learning Representations for Counterfactual Inference,,Performance evaluation; Performance evaluation,Justice; Explicability,Fairness; Explicability; Interpretability,Regression; Multi-class Classification,"3,2",Academic,Article; Code,Python,https://doi.org/10.48550/arXiv.1605.03661,2016,"Fredrik D. Johansson, Uri Shalit, David Sontag","https://bpauld.github.io/files/MLRG2.pdf

https://github.com/ankits0207/Learning-representations-for-counterfactual-inference-MyImplementation

https://github.com/vdorie/bartCause"
37,Generative Adversarial Networks (GANs) for synthetic dataset generation with binary classes,,,"Collection, understanding and preparation of data",Non-Maleficence,Reliability; Quality Data,Binary Classification,"3,1",Academic,Website; Code,Python,https://datasciencecampus.ons.gov.uk/projects/generative-adversarial-networks-gans-for-synthetic-dataset-generation-with-binary-classes/,2019,"Chaitanya Joshi, Ioannis Kaloskampis, Louisa Nolan",https://github.com/datasciencecampus/synthetic-data
38,Human Decisions and Machine Predictions,Human Decisions and Machine Predictions,,Performance evaluation,Beneficence,Responsibility; Social Good,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1093/qje/qjx032,2017,"Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, Sendhil Mullainathan",https://www.nber.org/system/files/working_papers/w23180/w23180.pdf
39,Adversarial Robustness - Theory and Practice,,,Model setup and training,Non-Maleficence,Security; Reliability,Regression; Multi-class Classification,4,Academic,Website; Code; Examples,Python,https://adversarial-ml-tutorial.org/,2018,"Zico Kolter, Aleksander Madry",
40,The fallacy of inscrutability,The fallacy of inscrutability,,Deployment and monitoring,Explicability,Interpretability; Explicability,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1098/rsta.2018.0084,2018,Joshua A. Kroll,
41,Accountable Algorithms,Accountable Algorithms,,Planning and design; Model setup and training; Deployment and monitoring,Non-Maleficence; Justice; Explicability,Justice; Fairness; Accountability; Well-being; Social Good,Does not apply,Does not apply,Academic,Article,Does not apply,https://collaborate.princeton.edu/en/publications/accountable-algorithms,2017,"Joshua A. Kroll, Joanna Huey, Solon Barocas, Edward W. Felten, Joel R. Reidenberg, David G. Robinson, Harlan Yu",https://scholarship.law.upenn.edu/cgi/viewcontent.cgi?article=9570&context=penn_law_review
42,Counterfactual Fairness,Counterfactual Fairness,,Model setup and training,Explicability,Explicability; Interpretability,Multi-class Classification,"3,5",Academic,Article; Code,R,https://doi.org/10.48550/arXiv.1703.06856,2017,"Matt J. Kusner, Joshua R. Loftus, Chris Russell, Ricardo Silva",https://github.com/mkusner/counterfactual-fairness
43,The Selective Labels Problem: Evaluating Algorithmic Predictions in the Presence of Unobservables,The Selective Labels Problem: Evaluating Algorithmic Predictions in the Presence of Unobservables,,Performance evaluation,Justice,Auditability,Multi-class Classification,Does not apply,Academic,Article,Unknown,https://doi.org/10.1145/3097983.3098066,2017,"Himabindu Lakkaraju, Jon Kleinberg, Jure Leskovec, Jens Ludwig, Sendhil Mullainathan",
44,"Fair, Transparent, and Accountable Algorithmic Decision-making Processes","Fair, Transparent, and Accountable Algorithmic Decision-making Processes",,Deployment and monitoring,Non-Maleficence,Responsibility; Transparency; Privacy,Does not apply,4,Academic; NGO,Article; Website,Does not apply,https://doi.org/10.1007/s13347-017-0279-x,2018,"Bruno Lepri, Nuria Oliver, Emmanuel Letouzé, Alex Pentland, Patrick Vinck","https://www.opalproject.org/

https://www.opalproject.org/resources

https://sci-hub.ru/10.1007/s13347-017-0279-x"
45,Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions,Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions,,Model setup and training; Model setup and training,Justice; Explicability,Explicability; Fairness; Interpretability,Multi-class Classification; Computer Vision,"3,6",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1710.04806,2017,"Oscar Li, Hao Liu, Chaofan Chen, Cynthia Rudin","https://github.com/OscarcarLi/PrototypeDL

https://github.com/mariusarvinte/FATML-MiniProject"
46,Learning Adversarially Fair and Transferable Representations,Learning Adversarially Fair and Transferable Representations,,Model setup and training,Justice,Fairness,Multi-class Classification,"3,8",Academic,Article; Code,Python,https://doi.org/10.48550/arXiv.1802.06309,2018,"David Madras, Elliot Creager, Toniann Pitassi, Richard Zemel",https://github.com/VectorInstitute/laftr
47,Privacy Principles: Towards a Common Privacy Audit Methodology,Privacy Principles: Towards a Common Privacy Audit Methodology,,Deployment and monitoring,Non-Maleficence,Auditability; Reliability; Privacy,Does not apply,"3,6",Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1007/978-3-319-22906-5_17,2015,"Eleni-Laskarina Makri, Costas Lambrinoudakis ",https://sci-hub.ru/10.1007/978-3-319-22906-5_17
48,Moral Machine - MIT,,,Businness and problem understanding,Justice,Fairness,Computer Vision,"4,2",Academic; NGO,Website,Does not apply,https://www.moralmachine.net,2016,"Iyad Rahwan, Jean-Francois Bonnefon, Azim Shariff, Edmond Awad, Sohan Dsouza, Paiju Chang, Danny Tang",
49,Economy Impact Model,,,Businness and problem understanding,Beneficence,Social Good; Well-being; Diversity; Inclusion,Does not apply,"3,6",NGO,Theoretical Framework,Does not apply,http://ethicskit.org/economy-impact-model.html,2019,"The Federation of Southern Cooperatives, Noisy Cricket Organization",https://ethicskit.org/tools.html
50,Adversarial Robustness Toolbox (ART),Adversarial Robustness Toolbox v1.0.0,,Performance evaluation; Deployment and monitoring,Non-Maleficence; Non-Maleficence,Security; Reliability; Privacy,Multi-class Classification; Computer Vision; Regression; Natural Language Processing,"4,6",Private,Article; Code,Python,https://doi.org/10.48550/arXiv.1807.01069,2018,"Maria-Irina Nicolae, Mathieu Sinn, Minh Ngoc Tran, Beat Buesser, Ambrish Rawat, Martin Wistuba, Valentina Zantedeschi, Nathalie Baracaldo, Bryant Chen, Heiko Ludwig, Ian M. Molloy, Ben Edwards","https://github.com/Trusted-AI/adversarial-robustness-toolbox

https://adversarial-robustness-toolbox.org/

https://developer.ibm.com/articles/applying-the-adversarial-robustness-toolbox/"
51,Data Ethics Canvas,,,Planning and design,Beneficence,Social Good; Human Rights,Does not apply,"4,2",NGO,Practical Framework; Guide,Does not apply,https://theodi.org/article/the-data-ethics-canvas-2021,2021,Open Data Institute (ODI),"https://docs.google.com/document/d/1OXSrA2KDMVkHroxs_8SUoQZ5Uv0eRhtNNtIl9g_Q47M/edit

https://docs.google.com/document/d/1MkvoAP86CwimbBD0dxySVCO0zeVOput_bu1A6kHV73M/edit"
52,Synthetic Data Pilot - ONS methodology working paper series number 16,,,"Collection, understanding and preparation of data",Non-Maleficence,Quality Data; Reliability; Privacy,Does not apply,"3,8",Public,Website; Article; Tool Compendium,R,https://www.ons.gov.uk/methodology/methodologicalpublications/generalmethodology/onsworkingpaperseries/onsmethodologyworkingpaperseriesnumber16syntheticdatapilot,2019,"Andrew G. Bates, Iva Špakulová, Iain Dove, Andrew Mealor","https://github.com/Iain-Dove-ONS/Synthetic_data_pilot

https://github.com/theodi/synthetic-data-tutorial/"
53,OpenMined,,,Model setup and training,Non-Maleficence,Security; Safety; Social Good; Privacy; Literacy,Does not apply,"4,6",NGO,Website; Code,Python; JavaScript; C++,https://www.openmined.org/,2017,"Andrew Trask, OpenMined Contributors","https://github.com/OpenMined

https://www.youtube.com/@OpenMinedOrg"
54,Personal AI Privacy Watchdog Could Help You Regain Control of Your Data,,,Deployment and monitoring,Autonomy,Literacy; Autonomy; Agency,Does not apply,4,Academic,App,Does not apply,https://www.technologyreview.com/2017/05/11/242790/personal-ai-privacy-watchdog-could-help-you-regain-control-of-your-data/,2017,"Mike Orcutt, Carnegie Mellon University","https://play.google.com/store/apps/details?id=cmu.scs.mobilecommerce.aerinzhang.ppa_study

https://apkpure.com/root-privacy-assistant/edu.cmu.mcom.ppa"
55,Questioning the assumptions behind fairness solutions,Questioning the assumptions behind fairness solutions,,Performance evaluation,Justice,Auditability; Fairness,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.48550/arXiv.1811.11293,2018,"Rebekah Overdorf, Bogdan Kulynych, Ero Balsa, Carmela Troncoso, Seda Gürses",
56,Explainable AI: Driving business value through greater understanding,,,Performance evaluation,Explicability,Interpretability; Explicability,Does not apply,4,Private,Theory Document; Guide,Does not apply,https://www.pwc.co.uk/services/risk/insights/explainable-ai.html,2021,PwC United Kingdom,https://www.pwc.co.uk/audit-assurance/assets/pdf/explainable-artificial-intelligence-xai.pdf
57,Scalable Private Learning with PATE,Scalable Private Learning with PATE,,"Collection, understanding and preparation of data",Non-Maleficence,Privacy; Reliability,Multi-class Classification,"4,2",Academic; Private,Article; Code,Python,https://doi.org/10.48550/arXiv.1802.08908,2018,"Nicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, Úlfar Erlingsson","https://github.com/tensorflow/privacy/tree/master/research/pate_2018/ICLR2018

https://github.com/tensorflow/privacy/tree/master/research

https://blog.tensorflow.org/2019/03/introducing-tensorflow-privacy-learning.html

https://www.tensorflow.org/responsible_ai/privacy/tutorials/classification_privacy"
58,Beyond Principles: A Process for Responsible Tech,,,Planning and design,Autonomy,Responsibility; Agency; Well-being,Does not apply,"4,2",Academic,Website; Tool Compendium; Practical Framework,Does not apply,https://medium.com/ethics-of-digital-experience/beyond-principles-a-process-for-responsible-tech-aefc921f7317,2019,"Dorian Peters, Rafael A. Calvo, Karina Vold, Diana Robinson","https://www.responsibletechdesign.com/

https://docs.google.com/presentation/d/e/2PACX-1vSgT-tM3H_FBCuuZVwDMvIpvLD-uuQfZi2h3MG6G35eekd7CF7LTASgg9AXEhK9Mb3MvhP0G3_E4rsI/pub?start=false&loop=false&delayms=600000&slide=id.p

https://ieeexplore.ieee.org/ielx7/8566059/8995808/09001063.pdf

https://www.positivecomputing.org/"
59,"Designing for Motivation, Engagement and Wellbeing in Digital Experience","Designing for Motivation, Engagement and Wellbeing in Digital Experience",,Planning and design,Autonomy,Responsibility; Well-being; Social Good,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.3389/fpsyg.2018.00797,2018,"Dorian Peters, Rafael A. Calvo, Richard M. Ryan","https://www.frontiersin.org/files/Articles/300159/fpsyg-09-00797-HTML/image_m/fpsyg-09-00797-t001.jpg

https://www.frontiersin.org/files/Articles/300159/fpsyg-09-00797-HTML/image_m/fpsyg-09-00797-t002.jpg"
60,The Machine Learning Reproducibility Checklist,Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program),,Deployment and monitoring,Non-Maleficence,Reliability; Reproducibility,Does not apply,4,Academic,Checklist; Article,Does not apply,https://doi.org/10.48550/arXiv.2003.12206,2019,"Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, Vincent Larivière, Alina Beygelzimer, Florence d'Alché-Buc, Emily Fox, Hugo Larochelle",https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf
61,Algorithmic Impact Assessments Report: A Practical Framework for Public Agency Accountability,,,Deployment and monitoring; Deployment and monitoring,Non-Maleficence; Explicability,Accountability; Auditability; Traceability; Social Good,Does not apply,4,NGO,Practical Framework,Does not apply,https://ainowinstitute.org/publication/algorithmic-impact-assessments-report-2,2018,"Dillon Reisman, Jason Schultz, Kate Crawford, Meredith Whittaker, AI Now Institute",https://ainowinstitute.org/wp-content/uploads/2023/04/aiareport2018.pdf
62,Responsible AI Licenses (RAIL),,,Deployment and monitoring,Non-Maleficence,Non-Maleficence; Prevention,Does not apply,"4,2",NGO,License,Does not apply,https://www.licenses.ai/ai-licenses,2019,"Danish Contractor, Daniel McDuff, Julia Katherine Haines, Brent Hecht, Carlos Muñoz Ferrandis, Jenny Lee, Joseph Lindley, Nick Vincent, Jesse Josua Benjamin, Hanlin Li",https://www.licenses.ai/blog/2022/8/18/naming-convention-of-responsible-ai-licenses
63,Data management and use: Governance in the 21st century - a British Academy and Royal Society project,,,Businness and problem understanding,Beneficence; Governance,Social Good; Quality Data,Does not apply,Does not apply,Academic,Report; Study Cases,Does not apply,https://royalsociety.org/topics-policy/projects/data-governance/,2017,"Royal Society, British Academy",https://royalsociety.org/-/media/policy/projects/data-governance/data-management-governance.pdf
64,When worlds collide: integrating different counterfactual assumptions in fairness,When worlds collide: integrating different counterfactual assumptions in fairness,,Performance evaluation,Justice,Fairness,Multi-class Classification,"3,4",Academic,Article; Code,Unknown,https://dl.acm.org/doi/10.5555/3295222.3295388,2017,"Chris Russell, Matt J. Kusner, Joshua Loftus, Ricardo Silva",
65,PySyft,A generic framework for privacy preserving deep learning,,Model setup and training,Non-Maleficence,Privacy; Security,Regression; Binary Classification; Multi-class Classification; Natural Language Processing,"4,6",Academic; NGO,Article; Code,Python,https://doi.org/10.48550/arXiv.1811.04017,2018,"Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso, Daniel Rueckert, Jonathan Passerat-Palmbach","https://github.com/OpenMined/PySyft

https://openmined.github.io/PySyft/"
66,Aequitas,Aequitas: A Bias and Fairness Audit Toolkit,,Performance evaluation,Justice,Fairness; Auditability,Regression; Binary Classification; Multi-class Classification,"4,4",Academic,Article; Code,Python,https://doi.org/10.48550/arXiv.1811.05577,2018,"Pedro Saleiro, Benedict Kuester, Loren Hinkson, Jesse London, Abby Stevens, Ari Anisfeld, Kit T. Rodolfa, Rayid Ghani","http://aequitas.dssg.io/

https://github.com/dssg/aequitas

http://www.datasciencepublicpolicy.org/our-work/tools-guides/aequitas/"
67,AI Ethics Cards,AI Needs an Ethical Compass - This tool can help,,Businness and problem understanding,Beneficence,Quality Data; Responsibility; Well-being,Does not apply,"3,8",NGO,Website; Practical Framework,Does not apply,https://www.ideo.com/blog/ai-needs-an-ethical-compass-this-tool-can-help,2019,"IDEO Organization, Ovetta Sampson, Michael Chapman","https://page.ideo.com/download-ai-ethics-cards

http://web.archive.org/web/20230131062043/https://www.ideo.com/blog/ai-needs-an-ethical-compass-this-tool-can-help"
68,Glass-Box: Voice-enabled Virtual Assistant,Glass-Box: Explaining AI Decisions With Counterfactual Statements Through Conversation With a Voice-enabled Virtual Assistant,,Deployment and monitoring; Performance evaluation,Justice; Explicability,Fairness; Explicability; Interpretability,Natural Language Processing,2,Academic,Article; Voice Assistant,Python,https://doi.org/10.24963/ijcai.2018/865,2018,"Kacper Sokol, Peter Flach",
69,Ethics and Privacy in AI and Big Data: Implementing Responsible Research and Innovation,Ethics and Privacy in AI and Big Data: Implementing Responsible Research and Innovation,,Businness and problem understanding,Beneficence; Governance,Social Good; Reliability; Well-being; Sustainability,Does not apply,4,Academic,Article; Tool Compendium,Does not apply,https://doi.org/10.1109/MSP.2018.2701164,2018,"Bernd Carsten Stahl, David Wright","https://rri-tools.eu/

https://rri-tools.eu/how-tos

https://rri-tools.eu/search-engine

https://sci-hub.se/10.1109/MSP.2018.2701164"
70,Development of privacy design patterns based on privacy principles and UML,Development of privacy design patterns based on privacy principles and UML,,Planning and design,Non-Maleficence,Privacy,Does not apply,3,Academic,Article; Code,UML; Java,https://doi.org/10.1109/SNPD.2017.8022748,2017,"Theeraporn Suphakul, Twittie Senivongse",https://sci-hub.ru/10.1109/SNPD.2017.8022748
71,TensorFlow Privacy,,,"Collection, understanding and preparation of data",Non-Maleficence,Privacy; Reliability,Regression; Multi-class Classification,"4,2",Private; Academic,Code; Examples,Python,https://github.com/tensorflow/privacy,2018,"Google, TensorFlow Community","https://github.com/tensorflow/privacy/blob/master/tutorials/walkthrough/README.md

https://github.com/tensorflow/privacy/tree/master/tutorials"
72,The Turing Way,,,Planning and design; Performance evaluation,Non-Maleficence; Explicability,Reproducibility; Explicability; Interpretability,Does not apply,"4,4",Public,Guide; Website; Book,Does not apply,https://github.com/alan-turing-institute/the-turing-way/,2020,"The Turing Way Community, The Alan Turing Institute","https://the-turing-way.netlify.app/index.html

https://www.turing.ac.uk/research/research-projects/turing-way"
73,An Ethical Framework for Evaluating Experimental Technology,An Ethical Framework for Evaluating Experimental Technology,,Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Businness and problem understanding,Beneficence; Non-Maleficence; Autonomy; Justice; Governance,Responsibility; Accountability; Agency; Fairness; Social Good; Privacy,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1007/s11948-015-9724-3,2015,Ibo van de Poel,
74,A Right to Reasonable Inferences: Re-Thinking Data Protection Law in the Age of Big Data and AI,A Right to Reasonable Inferences: Re-Thinking Data Protection Law in the Age of Big Data and AI,,Deployment and monitoring; Deployment and monitoring,Autonomy; Explicability; Governance,Agency; Explicability; Interpretability,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.7916/cblr.v2019i2.3424,2019,"Sandra Wachter, Brent Mittelstadt",
75,Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR,Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR,,Performance evaluation; Performance evaluation,Justice; Explicability,Fairness; Explicability; Interpretability,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.48550/arXiv.1711.00399,2017,"Sandra Wachter, Brent Mittelstadt, Chris Russell",
76,Wellcome Data Labs - Agile methodology,,,Businness and problem understanding,Beneficence,Social Good; Responsibility; Well-being,Does not apply,Does not apply,NGO,Website; Resource Compendium; Theoretical Framework,Does not apply,https://wellcome.org/news/new-method-ethical-data-science,2019,"Danil Mikhailov, Wellcome Data Labs Team","https://medium.com/wellcome-data/a-new-method-for-ethical-data-science-edb59e400ae9

https://medium.com/wellcome-data

https://medium.com/@katchja/agile-ethics-in-ai-why-we-need-a-new-design-process-for-benevolent-ai-3134b2932406"
77,What-If Tool,The What-If Tool: Interactive Probing of Machine Learning Models,,Performance evaluation; Performance evaluation,Justice; Explicability,Fairness; Explicability; Auditability,Regression; Binary Classification; Multi-class Classification; Multi-class Classification,"4,6",Private; Academic,Article; Code,Python,https://doi.org/10.1109/TVCG.2019.2934619,2019,"James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg, Fernanda Viegas, Jimbo Wilson, What-If Tool Community","https://github.com/pair-code/what-if-tool

https://pair-code.github.io/what-if-tool/"
78,Auditing Algorithms @Northeastern,,,Deployment and monitoring,Non-Maleficence,Reproducibility; Auditability,Does not apply,4,Academic,Website; Resource Compendium,Does not apply,https://personalization.ccs.neu.edu/,2017,"Algorithm Auditing Research Group, Christo Wilson",https://www.khoury.northeastern.edu/people/christo-wilson/
79,Fairness Constraints: Mechanisms for Fair Classification,Fairness Constraints: Mechanisms for Fair Classification,,Model setup and training,Justice,Fairness,Binary Classification,"3,8",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1507.05259,2015,"Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, Krishna P. Gummadi","https://github.com/mbilalzafar/fair-classification/tree/master/disparate_impact

https://github.com/mbilalzafar/fair-classification

https://fate-computing.mpi-sws.org/"
80,Visual Interpretability for Deep Learning: a Survey,Visual Interpretability for Deep Learning: a Survey,,Performance evaluation,Explicability,Explicability; Interpretability,Does not apply,Does not apply,Academic,Article; Resource Compendium,Does not apply,https://doi.org/10.48550/arXiv.1802.00614,2018,"Quanshi Zhang, Song-Chun Zhu",
81,Improving Social Responsibility of Artificial Intelligence by Using ISO 26000,Improving Social Responsibility of Artificial Intelligence by Using ISO 26000,,Businness and problem understanding,Beneficence; Governance,Responsibility; Social Good,Does not apply,Does not apply,Academic,Article; Guide; Standard,Does not apply,https://doi.org/10.1088/1757-899X/428/1/012049,2018,Wei-Wei Zhao,https://www.iso.org/iso-26000-social-responsibility.html
82,Ten simple rules for responsible big data research,Ten simple rules for responsible big data research,,Businness and problem understanding,Non-Maleficence,Responsibility; Reliability; Prevention,Does not apply,Does not apply,Academic,Article; Guidelines,Does not apply,https://doi.org/10.1371/journal.pcbi.1005399,2017,"Matthew Zook, Solon Barocas, danah boyd, Kate Crawford, Emily Keller, Seeta Peña Gangadharan, Alyssa Goodman, Rachelle Hollander, Barbara A. Koenig, Jacob Metcalf, Arvind Narayanan, Alondra Nelson, Frank Pasquale",
83,SCRT Labs (Enigma),Enigma: Decentralized Computation Platform with Guaranteed Privacy,,"Collection, understanding and preparation of data",Non-Maleficence,Privacy,Does not apply,"4,6",Private; Academic,Article; Website,Does not apply,https://doi.org/10.48550/arXiv.1506.03471,2015,"Guy Zyskind, Oz Nathan, Alex Pentland, SCRT Labs Team","https://www.scrtlabs.com/

https://scrt.network/blog/introducing-scrt-labs-an-evolution-of-enigma/

https://medium.com/paradigm-research/enigma-detailed-review-on-the-project-dc713a17f5d2

https://scrt.network/"
84,"Risks, Harms and Benefits Assessment",,,Businness and problem understanding; Planning and design; Deployment and monitoring,Justice; Justice; Justice,Auditability; Prevention; Safety,Does not apply,4,NGO,Guide; Checklist,Does not apply,https://www.unglobalpulse.org/policy/risk-assessment/,2017,UN Global Pulse,
85,"AI and Big Data: A blueprint for a human rights, social and ethical impact assessment","AI and Big Data: A blueprint for a human rights, social and ethical impact assessment",,Businness and problem understanding; Planning and design,Justice; Beneficence,Auditability; Human Rights,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1016/j.clsr.2018.05.017,2018,Alessandro Mantelero,
86,"Ethical Data and Information Management: Concepts, Tools and Methods","Ethical Data and Information Management: Concepts, Tools and Methods",,"Collection, understanding and preparation of data",Non-Maleficence; Governance,Privacy; Quality Data; Reliability,Does not apply,Does not apply,Academic; Private,Book; Guide,Does not apply,https://dl.acm.org/doi/book/10.5555/3265200,2018,"Katherine O'Keefe, Daragh O. Brien",https://sci-hub.ru/978-0-7494-8204-6
87,AI Procurement in a Box,,,Businness and problem understanding; Deployment and monitoring,Non-Maleficence; Justice,Privacy; Reliability; Responsibility; Auditability,Does not apply,"4,2",NGO,Guide; Study Cases; Tool Compendium; Guidelines,Does not apply,https://www.weforum.org/reports/ai-procurement-in-a-box/,2019,World Economic Forum (WEF),
88,Algorithmic Impact Assessments Tool,,,Businness and problem understanding; Planning and design; Deployment and monitoring,Beneficence; Beneficence; Justice,Auditability; Trade-offs; Social Good; Well-being,Does not apply,"4,4",Public,Website; Practical Framework,Does not apply,https://www.canada.ca/en/government/system/digital-government/digital-government-innovations/responsible-use-ai/algorithmic-impact-assessment.html,2019,"Noel Corriveau, Ashley Casovan, Benoit Deshaies, Government of Canada",https://open.canada.ca/data/en/dataset/5423054a-093c-4239-85be-fa0b36ae0b2e
89,Code of Ethics for Data-Based Value Creation,,,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Non-Maleficence; Non-Maleficence; Autonomy; Justice; Justice; Autonomy; Governance,Transparency; Fairness; Accountability; Agency; Reliability; Privacy; Responsibility; Quality Data,Does not apply,Does not apply,NGO,Code of Ethics,Does not apply,https://digitalcollection.zhaw.ch/bitstream/11475/24226/3/2020_Christen-etal_Ethical-Codex_Basics.pdf,2019,"Markus Christen, Christoph Heitz, Tom Kleiber, Michele Lois, Swiss Alliance for Data-Intensive Services",https://data-innovation.org/data-ethics/
90,IBM Watson Studio,,,Model setup and training; Performance evaluation; Deployment and monitoring,Non-Maleficence; Justice; Non-Maleficence,Reliability; Fairness; Auditability; Trade-offs,Regression; Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,"4,8",Private,Code; Website; Tool Compendium,Python; R; Scala,https://www.ibm.com/cloud/watson-studio,2019,IBM,"https://developer.ibm.com/components/watson-studio/

https://www.ibm.com/cloud/watson-studio/model-risk-management"
91,The Ethics Certification Program for Autonomous and Intelligent Systems (ECPAIS),,,Planning and design; Planning and design,Non-Maleficence; Justice; Governance,Transparency; Reliability; Fairness; Social Good; Well-being,Does not apply,Does not apply,Private,Certification; Course,Does not apply,https://standards.ieee.org/industry-connections/ecpais/,2019,Institute of Electrical and Electronics Engineers (IEEE),
92,Judgment Call,Judgment Call the Game: Using Value Sensitive Design and Design Fiction to Surface Ethical Concerns Related to Technology,,"Planning and design; Collection, understanding and preparation of data",Beneficence; Justice,Inclusion; Well-being; Social Good; Trade-offs,Does not apply,4,Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1145/3322276.3323697,2019,"Stephanie Ballard, Karen M. Chappell, Kristen Kennedy","https://learn.microsoft.com/en-us/azure/architecture/guide/responsible-innovation/judgmentcall

http://houseofmethods.com/pdf/microsoft-judgment-call.pdf"
93,Model Ethical Data Impact Assessment,Ethical Data Impact Assessments and Oversight Models,,Businness and problem understanding; Deployment and monitoring,Non-Maleficence; Justice,Auditability; Privacy,Does not apply,"3,8",NGO,Guide; Practical Framework,Does not apply,https://secureservercdn.net/192.169.221.188/b1f.827.myftpupload.com/wp-content/uploads/2020/04/Model-Ethical-Data-Impact-Assessment-January-2019-002.pdf,2019,The Information Accountability Foundation,https://www.pcpd.org.hk/misc/files/Ethical_Accountability_Framework_Detailed_Support.pdf
94,"Model AI Governance Framework, Second Edition",,,Businness and problem understanding; Planning and design; Deployment and monitoring,Beneficence; Non-Maleficence; Autonomy; Governance,Human Rights; Social Good; Inclusion; Well-being; Auditability; Reliability; Agency,Does not apply,"4,2",Public,Practical Framework; Guide,Does not apply,https://www.pdpc.gov.sg/-/media/files/pdpc/pdf-files/resource-for-organisation/ai/sgmodelaigovframework2.pdf,2019,The Personal Data Protection Commission (PDPC) of Singapore,"https://www.pdpc.gov.sg/Help-and-Resources/2020/01/Model-AI-Governance-Framework

https://oecd.ai/en/wonk/singapores-model-framework-to-balance-innovation-and-trust-in-ai"
95,AI Blindspot,"AI Blindspot: A Discovery Process for preventing, detecting, and mitigating bias in AI systems",,Businness and problem understanding; Planning and design,Non-Maleficence; Justice,Trade-offs; Responsibility; Prevention; Fairness,Does not apply,4,Academic,Practical Framework; Website; Guide,Does not apply,https://aiblindspot.media.mit.edu/,2020,"Ania Calderon, Dan Taber, Hong Qu, Jeff Wen","https://aiblindspot.media.mit.edu/AL.html

https://medium.com/berkman-klein-center/ai-blindspot-be458ef0ab89

https://aiblindspot.media.mit.edu/images/AI_Cards_2021.pdf"
96,Algorithm Register,,,Deployment and monitoring,Non-Maleficence,Reproducibility; Auditability; Accountability; Transparency,Does not apply,4,Public,Website; Resource Compendium,Does not apply,https://algoritmeregister.amsterdam.nl/,2020,City of Amsterdam,https://algoritmeregister.amsterdam.nl/en/ai-register/
97,Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic auditing,Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic auditing,,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Non-Maleficence; Non-Maleficence; Justice; Justice; Justice; Non-Maleficence; Governance,Accountability; Auditability; Social Good,Does not apply,Does not apply,Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1145/3351095.3372873,2020,"Inioluwa Deborah Raji, Andrew Smart, Rebecca N. White, Margaret Mitchell, Timnit Gebru, Ben Hutchinson, Jamila Smith-Loud, Daniel Theron, Parker Barnes",https://drive.google.com/drive/folders/1NUSTvWObrDSkjmWTrDCxKoPkXmypguiv
98,Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI,Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI,,Businness and problem understanding; Planning and design; Model setup and training; Performance evaluation; Deployment and monitoring,Non-Maleficence; Justice; Justice; Justice; Non-Maleficence,Reliability; Fairness,Does not apply,"3,8",Academic; Private,Article; Checklist,Does not apply,https://doi.org/10.1145/3313831.3376445,2020,"Michael A. Madaio, Luke Stark, Jennifer Wortman Vaughan, Hanna Wallach","https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/

https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA"
99,Corporate Digital Responsibility (CDR),Corporate digital responsibility,,Businness and problem understanding; Planning and design; Deployment and monitoring,Non-Maleficence; Non-Maleficence; Non-Maleficence,Responsibility; Accountability; Reliability,Does not apply,Does not apply,Academic,Article; Theoretical Framework,Does not apply,https://doi.org/10.1016/j.jbusres.2019.10.006,2020,"Lara Lobschat, Benjamin Mueller, Felix Eggers, Laura Brandimarte, Sarah Diefenbach, Mirja Kroschke, Jochen Wirtz",https://corporatedigitalresponsibility.net/
100,Data Ethics Framework (UK),,,Businness and problem understanding; Planning and design,Non-Maleficence; Justice,Privacy; Responsibility; Transparency; Accountability; Fairness,Does not apply,"4,4",Public,Guide; Code of Practice,Does not apply,https://www.gov.uk/government/publications/data-ethics-framework,2020,Central Digital & Data Office (UK),https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/923108/Data_Ethics_Framework_2020.pdf
101,Empowering AI Leadership,,,Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Justice; Governance,Sustainability; Social Good; Inclusion; Diversity; Privacy; Security; Reliability; Fairness; Auditability,Does not apply,"4,4",NGO,Website; Guide; Practical Framework; Resource Compendium,Does not apply,https://express.adobe.com/page/RsXNkZANwMLEf/,2020,World Economic Forum,"https://www.weforum.org/reports/empowering-ai-leadership-ai-c-suite-toolkit

https://www3.weforum.org/docs/WEF_C4IR_Case_Study_Empowering_AI_leadership_2020.pdf"
102,7000-2021 - IEEE Standard Model Process for Addressing Ethical Concerns during System Design,7000-2021 - IEEE Standard Model Process for Addressing Ethical Concerns during System Design,,Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Justice; Governance,Sustainability; Responsibility; Privacy; Transparency; Fairness; Social Good,Does not apply,4,Private,Standard,Does not apply,https://doi.org/10.1109/IEEESTD.2021.9536679,2020,Institute of Electrical and Electronics Engineers (IEEE),"https://standards.ieee.org/ieee/7000/6781/

https://engagestandards.ieee.org/ieee-7000-2021-for-systems-design-ethical-concerns.html"
103,Standard Clauses For Procurement Of Trustworthy Algorithmic Systems,,,Businness and problem understanding; Businness and problem understanding,Non-Maleficence; Explicability,Transparency; Explicability; Security; Responsibility,Does not apply,Does not apply,Public,Contractual Terms,Does not apply,https://www.amsterdam.nl/innovation/digitalisation-technology/algorithms-ai/contractual-terms-for-algorithms/,2020,City of Amsterdam,
104,Toward situated interventions for algorithmic equity: lessons from the field,Toward situated interventions for algorithmic equity: lessons from the field,,Businness and problem understanding; Planning and design; Deployment and monitoring,Non-Maleficence; Non-Maleficence; Justice,Accountability; Fairness,Does not apply,Does not apply,Academic,Article; Case Studies,Does not apply,https://doi.org/10.1145/3351095.3372874,2020,"Michael Katell, Meg Young, Dharma Dailey, Bernease Herman, Vivian Guetler, Aaron Tam, Corinne Bintz, Daniella Raz, P. M. Krafft","https://www.aclu-wa.org/AEKit

https://designjustice.org/principles-overview"
105,Value-based Engineering for Ethics by Design,Value-based Engineering for Ethics by Design,,Businness and problem understanding; Planning and design,Beneficence; Beneficence,Social Good; Responsibility,Does not apply,Does not apply,Private,Article; Case Studies,Does not apply,https://doi.org/10.48550/arXiv.2004.13676,2020,"Sarah Spiekermann, Till Winkler",https://standards.ieee.org/ieee/7000/6781/
106,AI Incident Database,,,"Planning and design; Collection, understanding and preparation of data; Deployment and monitoring",Non-Maleficence; Non-Maleficence; Non-Maleficence,Accountability; Prevention,Does not apply,"4,2",NGO,Website; Resource Compendium,Does not apply,https://incidentdatabase.ai/,2020,The Partnership on AI,
107,White Paper on Data Ethics in Public Procurement of AI-based Services and Solutions,,,Businness and problem understanding,Beneficence,Social Good; Human Rights; Responsibility,Does not apply,4,NGO,White Paper; Guide,Does not apply,https://www.dataethics.eu/wp-content/uploads/dataethics-whitepaper-april-2020.pdf,2020,"Gry Hasselbalch, Birgitte Kofod Olsen, Pernille Tranberg","https://ec.europa.eu/futurium/en/european-ai-alliance/white-paper-data-ethics-public-procurement-ai-based-services-and-solutions.html

https://dataethics.eu/publicprocurement/"
108,Responsible AI,,,"Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Non-Maleficence; Justice; Justice; Explicability; Non-Maleficence,Security; Reliability; Fairness; Explicability; Interpretability; Transparency; Privacy,Regression; Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,"4,4",Private,Website; Principles; Tool Compendium; Resource Compendium,Does not apply,https://www.tensorflow.org/responsible_ai,2020,"TensorFlow, Google",https://ai.google/responsibility/principles/
109,Responsible AI Resources,,,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Beneficence; Autonomy; Non-Maleficence; Justice; Explicability; Autonomy,Social Good; Well-being; Security; Privacy; Reliability; Fairness; Transparency; Explicability; Interpretability; Inclusion; Diversity; Auditability; Literacy,Regression; Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,"4,6",Private,Website; Tool Compendium; Resource Compendium; Principles,Does not apply,https://www.microsoft.com/en-us/ai/responsible-ai-resources,2020,Microsoft,https://www.microsoft.com/en-us/ai/our-approach
110,Trustworthy AI - AI Ethics,,,"Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Non-Maleficence; Justice; Justice; Explicability; Non-Maleficence,Security; Reliability; Fairness; Explicability; Interpretability; Transparency; Privacy; Auditability,Regression; Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,"4,6",Private,Website; Resource Compendium; Tool Compendium; Principles,Does not apply,https://research.ibm.com/topics/trustworthy-ai,2020,IBM,"https://www.ibm.com/artificial-intelligence/ethics

https://www.ibm.com/products/cloud-pak-for-data/ai-governance

https://www.ibm.com/products/cloud-pak-for-data/data-integration

https://www.ibm.com/products/cloud-pak-for-data/governance

https://www.ibm.com/products/watsonx-governance

https://www.ibm.com/products/openpages"
111,"Artificial Intelligence Ethics and Safety: practical tools for creating ""good"" models","Artificial Intelligence Ethics and Safety: practical tools for creating ""good"" models",,Businness and problem understanding; Planning and design; Deployment and monitoring,Non-Maleficence; Justice; Explicability,Accountability; Transparency; Security; Explicability; Auditability; Social Good; Fairness,Does not apply,Does not apply,NGO,Guide; Article; Tool Compendium,Does not apply,https://deepai.org/publication/artificial-intelligence-ethics-and-safety-practical-tools-for-creating-good-models,2021,Nicholas Kluge Corrêa,"https://arxiv.org/abs/2112.11208

https://github.com/joojs/fairface

https://futurescope.digicatapult.org.uk/wp-content/uploads/2023/04/DC_AI_Ethics_Framework-2021.pdf

https://www.airespucrs.org/en/post/ai-safety-watch-advanced-artificial-intelligence-r-d-2020"
112,Ethics in AI research papers and articles,,,Businness and problem understanding; Planning and design,Beneficence; Autonomy,Social Good; Agency; Well-being; Trust,Does not apply,4,Academic,Website; Resource Compendium,Does not apply,https://blog.salesforceairesearch.com/ethics-in-ai-research-papers-and-articles/,2019,Kathy Baxter,
113,A Survey on Ethical Principles of AI and Implementations,A Survey on Ethical Principles of AI and Implementations,,Businness and problem understanding; Planning and design; Deployment and monitoring,Non-Maleficence; Justice; Explicability,Accountability; Transparency; Security; Explicability; Auditability; Fairness,Does not apply,Does not apply,Academic,Article; Guide; Tool Compendium,Does not apply,https://doi.org/10.1109/SSCI47803.2020.9308437,2020,"Jianlong Zhou, Fang Chen, Adam Berry, Mike Reed, Shujia Zhang, Siobhan Savage",https://sci-hub.ru/10.1109/SSCI47803.2020.9308437
114,Amazon SageMaker Clarify,Amazon SageMaker Clarify: Machine Learning Bias Detection and Explainability in the Cloud,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Justice; Justice; Explicability; Explicability,Fairness; Transparency; Auditability; Explicability; Interpretability,Regression; Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,"4,6",Private,Article; Code; Website,Python,https://arxiv.org/abs/2109.03285,2021,"Michaela Hardt, Xiaoguang Chen, Xiaoyi Cheng, Michele Donini, Jason Gelman, Satish Gollaprolu, John He, Pedro Larroy, Xinyu Liu, Nick McCarthy, Ashish Rathi, Scott Rees, Ankit Siva, ErhYuan Tsai, Keerthan Vasist, Pinar Yilmaz, Muhammad Bilal Zafar, Sanjiv Das, Kevin Haas, Tyler Hill, Krishnaram Kenthapadi","https://aws.amazon.com/sagemaker/clarify

https://github.com/aws/amazon-sagemaker-clarify

https://aws.amazon.com/sagemaker/data-wrangler"
115,Alibi Explain,Alibi explain: algorithms for explaining machine learning models,,Performance evaluation,Explicability,Explicability; Interpretability,Regression; Multi-class Classification; Computer Vision,"4,4",Academic,Article; Code,Python,https://dl.acm.org/doi/10.5555/3546258.3546439,2019,"Janis Klaise, Arnaud Van Looveren, Giovanni Vacanti, Alexandru Coca","https://github.com/SeldonIO/alibi

https://docs.seldon.io/projects/alibi/en/stable/overview/algorithms.html"
116,Fairlearn,A Reductions Approach to Fair Classification,,Model setup and training; Performance evaluation,Justice; Justice,Fairness,Regression; Binary Classification; Multi-class Classification,"4,4",NGO; Academic,Article; Code; Website,Python,https://doi.org/10.48550/arXiv.1803.02453,2018,"Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John Langford, Hanna Wallach",https://fairlearn.org/
117,LIME,"""Why Should I Trust You?"": Explaining the Predictions of Any Classifier",,Performance evaluation,Explicability,Explicability; Interpretability,Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,"4,4",Academic,Article; Code,Python,https://doi.org/10.48550/arXiv.1602.04938,2016,"Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin","https://github.com/marcotcr/lime

https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/"
118,TransparentAI,,,"Collection, understanding and preparation of data; Collection, understanding and preparation of data; Performance evaluation; Deployment and monitoring",Non-Maleficence; Justice; Explicability; Beneficence,Quality Data; Reliability; Fairness; Explicability; Interpretability; Sustainability,Regression; Multi-class Classification; Binary Classification,"4,2",Academic,Code,Python,https://github.com/Nathanlauga/transparentai,2020,Nathan Lauga,
119,Shapash,,,Performance evaluation; Performance evaluation,Justice; Explicability,Auditability; Explicability; Interpretability,Regression; Binary Classification; Multi-class Classification,"4,6",NGO; Academic,Code; Website,Python,https://github.com/MAIF/shapash,2020,MAIF Data Scientists,https://maif.github.io/shapash/
120,FairTest,FairTest: Discovering Unwarranted Associations in Data-Driven Applications,,Performance evaluation,Justice,Fairness,Multi-class Classification; Regression,4,Academic,Article; Code,Python,https://doi.org/10.48550/arXiv.1510.02377,2016,"Florian Tramèr, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, Jean-Pierre Hubaux, Mathias Humbert, Ari Juels, Huang Lin",https://github.com/columbia/fairtest
121,FairML,FairML: Auditing Black-Box Predictive Models,,Performance evaluation,Justice,Fairness; Auditability,Binary Classification,"3,8",Academic,Code,Python,https://github.com/adebayoj/fairml,2016,"Julius Adebayo, Micha Gorelick",
122,DALEX,moDel Agnostic Language for Exploration and eXplanation,,Performance evaluation; Deployment and monitoring,Justice; Explicability,Fairness; Auditability; Explicability; Interpretability,Regression; Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,"4,6",Academic,Article; Code; Website,Python; R,https://github.com/ModelOriented/DALEX,2018,"Hubert Baniecki, Wojciech Kretowicz, Piotr Piatyszek, Jakub Wisniewski, Przemyslaw Biecek","https://dalex.drwhy.ai

https://www.jmlr.org/papers/volume19/18-416/18-416.pdf

https://www.jmlr.org/papers/volume22/20-1473/20-1473.pdf"
123,Ethik,Explaining Machine Learning Models using Entropic Variable Projection,,Performance evaluation; Performance evaluation,Justice; Explicability,Fairness; Explicability; Interpretability,Binary Classification; Multi-class Classification; Computer Vision,"4,1",Academic,Code; Website; Article,Python,https://doi.org/10.48550/arXiv.1810.07924,2019,"François Bachoc, Fabrice Gamboa, Max Halford, Vincent Lefoulon, Jean-Michel Loubes, Laurent Risser","https://github.com/XAI-ANITI/ethik

https://xai-aniti.github.io/ethik/

https://gems-ai.aniti.fr/"
124,InterpretML,InterpretML: A Unified Framework for Machine Learning Interpretability,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Explicability,Quality Data; Auditability; Explicability; Interpretability,Binary Classification; Multi-class Classification; Regression,"4,6",Private; Academic,Article; Code; Website,Python,https://doi.org/10.48550/arXiv.1909.09223,2019,"Harsha Nori, Samuel Jenkins, Paul Koch, Rich Caruana","https://interpret.ml

https://github.com/interpretml/interpret"
125,Responsible Tech Playbook,,,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Beneficence; Non-Maleficence; Non-Maleficence; Justice; Explicability; Autonomy,Social Good; Sustainability; Fairness; Auditability; Agency; Explicability; Interpretability,Does not apply,"4,4",Public,Guide; Playbook; Tool Compendium,Does not apply,https://www.thoughtworks.com/en-us/about-us/social-change/responsible-tech-playbook,2021,Thoughtworks,https://www.thoughtworks.com/content/dam/thoughtworks/documents/e-book/tw_ebook_responsible_tech_playbook_2021.pdf
126,Fairness and Machine Learning: Limitations and Opportunities,Fairness and Machine Learning: Limitations and Opportunities,,Businness and problem understanding; Planning and design,Beneficence; Justice,Social Good; Well-being; Fairness,Does not apply,Does not apply,Academic,Book,Does not apply,https://fairmlbook.org/,2019,"Solon Barocas, Moritz Hardt, Arvind Narayanan",https://fairmlbook.org/pdf/fairmlbook.pdf
127,Practical Data Ethics,,,Businness and problem understanding; Businness and problem understanding; Performance evaluation,Beneficence; Non-Maleficence; Justice,Social Good; Privacy; Fairness; Literacy,Does not apply,"4,2",Academic,Course; Resource Compendium; Tool Compendium,Python,https://ethics.fast.ai/,2020,fast.ai,https://github.com/fastai/fastbook
128,Dealing with Bias and Fairness in Data Science Systems: A Practical Hands-on Tutorial,,,Businness and problem understanding; Performance evaluation,Beneficence; Justice,Social Good; Fairness; Auditability; Literacy,Does not apply,"4,2",Academic,Tutorial; Resource Compendium; Case Studies,Python,https://dssg.github.io/fairness_tutorial/,2020,"Pedro Saleiro, Kit T. Rodolfa, Rayid Ghani","https://textbook.coleridgeinitiative.org/chap-bias.html

https://textbook.coleridgeinitiative.org

https://github.com/dssg/fairness_tutorial"
129,Ethics as a Service: A Pragmatic Operationalisation of AI Ethics,Ethics as a Service: A Pragmatic Operationalisation of AI Ethics,,Planning and design,Beneficence,Social Good; Responsibility,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1007/s11023-021-09563-w,2021,"Jessica Morley, Anat Elhalal, Francesca Garcia, Libby Kinsey, Jakob Mökander, Luciano Floridi",
130,Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way,Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way,,Businness and problem understanding; Planning and design,Beneficence; Beneficence,Social Good; Responsibility; Literacy,Does not apply,Does not apply,Academic,Book; Resource Compendium,Does not apply,https://doi.org/10.1007/978-3-030-30371-6,2019,Virginia Dignum,https://sci-hub.se/10.1007/978-3-030-30371-6
131,"Ethical AI frameworks, tool kits, principles, and certifications - Oh my!",,,Businness and problem understanding; Planning and design,Beneficence; Autonomy,Social Good; Agency; Well-being; Trust; Literacy,Does not apply,"4,1",Academic,Website; Resource Compendium; Tool Compendium,Does not apply,https://blog.salesforceairesearch.com/frameworks-tool-kits-principles-and-oaths-oh-my/,2019,Kathy Baxter,
132,Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector,Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector,,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data; Performance evaluation; Deployment and monitoring",Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Social Good; Sustainability; Safety; Privacy; Reliability; Fairness; Auditability; Transparency; Interpretability; Responsibility,Does not apply,4,Academic,Guide; Tool Compendium; Resource Compendium,Does not apply,https://doi.org/10.5281/zenodo.3240529,2019,"David Leslie, The Alan Turing Institute","https://www.turing.ac.uk/news/publications/understanding-artificial-intelligence-ethics-and-safety

https://www.turing.ac.uk/sites/default/files/2019-06/understanding_artificial_intelligence_ethics_and_safety.pdf

https://www.turing.ac.uk/opportunities/skills-turing/learning-turing"
133,Privacy Meter,,,Model setup and training; Performance evaluation,Non-Maleficence; Justice,Privacy; Reliability; Security; Auditability,Regression; Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,"4,3",Academic,Code; Article,Python,https://github.com/privacytrustlab/ml_privacy_meter,2020,"NUS Data Privacy, Trustworthy Machine Learning Lab","https://doi.org/10.48550/arXiv.2111.09679

https://doi.org/10.48550/arXiv.2007.09339

https://doi.org/10.1109/SP.2019.00065

https://doi.org/10.1109/SP.2017.41

https://www.intel.com/content/www/us/en/developer/articles/technical/how-openfl-and-privacy-meter-empower-data-privacy.html

https://github.com/securefederatedai/openfl"
134,Learning Interpretability Tool (LIT),"The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models",,Performance evaluation,Explicability,Explicability; Interpretability,Regression; Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,"4,6",Private; Academic,Article; Code; Website,Python,https://doi.org/10.18653/v1/2020.emnlp-demos.15,2020,"Ian Tenney, James Wexler, Jasmijn Bastings, Tolga Bolukbasi, Andy Coenen, Sebastian Gehrmann, Ellen Jiang, Mahima Pushkarna, Carey Radebaugh, Emily Reif, Ann Yuan","https://github.com/pair-code/lit

https://pair-code.github.io/lit/"
135,Saliency,,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Computer Vision,"4,2",Private; Academic,Code; Examples,Python,https://github.com/PAIR-code/saliency,2019,Google PAIR Team,https://pair-code.github.io/saliency
136,System Cards,System-Level Transparency of Machine Learning,,Performance evaluation; Deployment and monitoring,Explicability; Explicability,Traceability; Explicability; Transparency,Does not apply,4,Private,Article; Website,Does not apply,https://ai.facebook.com/research/publications/system-level-transparency-of-machine-learning,2022,"Bilal Alsallakh, Adeel Cheema, Chavez Procope, David Adkins, Emily McReynolds, Erin Wang, Grace Pehl, Nekesha Green, Polina Zvyagina","https://ai.facebook.com/tools/system-cards/

https://ai.facebook.com/blog/system-cards-a-new-resource-for-understanding-how-ai-systems-work/

https://arxiv.org/abs/2204.13582"
137,An Ethical Toolkit for Engineering/Design Practice,,,Planning and design; Planning and design,Beneficence; Justice,Social Good; Responsibility; Auditability,Does not apply,Does not apply,Academic,Guide; Tool Compendium; Theory Document,Does not apply,https://www.scu.edu/ethics-in-technology-practice/ethical-toolkit/,2018,"Shannon Vallor, Regis McKenna, Dianne McKenna","https://www.scu.edu/media/ethics-center/technology-ethics/Ethics-Toolkit.pdf

https://www.scu.edu/ethics/"
138,HAX Toolkit,Human-AI Experience (HAX) Toolkit,,Planning and design,Beneficence,Social Good; Well-being,Does not apply,"4,6",Private,Website; Tool Compendium; Guidelines; Playbook,Does not apply,https://www.microsoft.com/en-us/haxtoolkit/,2019,Microsoft,"https://www.microsoft.com/en-us/haxtoolkit/toolkit-overview/

https://www.microsoft.com/en-us/research/project/hax-toolkit/"
139,Algorithmic Accountability Policy Toolkit,,,Planning and design; Deployment and monitoring,Non-Maleficence; Explicability,Accountability; Reliability; Transparency; Traceability,Does not apply,4,NGO,Tool Compendium; Resource Compendium; Report; Guide,Does not apply,https://ainowinstitute.org/publication/algorithmic-accountability-policy-toolkit,2018,AI Now Institute,https://ainowinstitute.org/wp-content/uploads/2023/04/aap-toolkit.pdf
140,Responsible AI: AI you can trust,PwC's Responsible AI: AI you can trust,,"Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Beneficence; Non-Maleficence; Justice; Justice; Explicability; Governance,Social Good; Responsibility; Security; Safety; Privacy; Fairness; Explicability; Interpretability,Does not apply,"4,5",Private,Website,Does not apply,https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai.html,2019,PwC United Kingdom,"https://www.pwcresearch.com/uc/RegAI2020/ospe.php?SES=3eaa06c108efa6801d68ba1320631f3c&syid=54769&sid=54770&act=start&js=15&flash=0&devicetype=0

https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai/pwc-responsible-ai.pdf

https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai/pwc-responsible-ai-maturing-from-theory-to-practice.pdf"
141,Algorithmic Equity Toolkit (AEKit),,,Businness and problem understanding; Performance evaluation; Performance evaluation; Deployment and monitoring,Non-Maleficence; Justice; Explicability; Explicability,Traceability; Transparency; Reliability; Prevention,Does not apply,4,Academic; NGO,Tool Compendium; Guide; Website,Does not apply,https://www.aclu-wa.org/AEKit,2019,"Bissan Barghouti, Corinne Bintz, Dharma Dailey, Micah Epstein, Vivian Guetler, Bernease Herman, Pa Ousman Jobe, Michael Katell, P. M. Krafft, Jennifer Lee, Shankar Narayan, Franziska Putz, Daniella Raz, Brian Robick, Aaron Tam, Abiel Woldu, Meg Young, Tech Fairness Coalition, ACLU of Washington",https://critplat.org/aekit-faq/
142,"Diversity Toolkit: A Guide to Discussing Identity, Power and Privilege",,,Businness and problem understanding; Businness and problem understanding,Beneficence; Justice,Human Rights; Social Good; Inclusion; Diversity; Fairness,Does not apply,Does not apply,Academic,Guide; Website; Resource Compendium,Does not apply,https://msw.usc.edu/mswusc-blog/diversity-workshop-guide-to-discussing-identity-power-and-privilege/,2020,University of Southern California,
143,audit-AI,,,Performance evaluation,Justice,Fairness; Auditability,Regression; Binary Classification; Multi-class Classification,"3,8",Private,Code,Python,https://github.com/pymetrics/audit-ai,2019,Data Science Team (Pymetrics),
144,PROBAST,PROBAST: A Tool to Assess Risk of Bias and Applicability of Prediction Model Studies: Explanation and Elaboration,,Businness and problem understanding,Justice,Fairness; Auditability,Does not apply,Does not apply,Academic,Article; Practical Framework,Does not apply,https://doi.org/10.7326/M18-1376,2019,"Robert F. Wolff, Karel G.M. Moons, Richard D. Riley, Penny F. Whiting, Marie Westwood, Gary S. Collins, Johannes B. Reitsma, Jos Kleijnen, Sue Mallett","https://www.probast.org/wp-content/uploads/2020/02/PROBAST_20190515.pdf

https://www.probast.org/"
145,deon,deon: An ethics checklist for data scientists,,Businness and problem understanding; Planning and design,Beneficence; Non-Maleficence,Social Good; Responsibility; Reliability,Does not apply,"4,1",Private; Public; NGO,Code; Checklist,Python,https://github.com/drivendataorg/deon,2018,DrivenData Team,https://deon.drivendata.org/
146,AI Fairness 360 (AIF360),"AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias",,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Justice; Justice; Justice,Fairness; Auditability,Binary Classification; Multi-class Classification,"4,5",Private,Article; Code; Website,Python; R,https://doi.org/10.48550/arXiv.1810.01943,2018,"Rachel K. E. Bellamy, Kuntal Dey, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, Aleksandra Mojsilovic, Seema Nagar, Karthikeyan Natesan Ramamurthy, John Richards, Diptikalyan Saha, Prasanna Sattigeri, Moninder Singh, Kush R. Varshney, Yunfeng Zhang, IBM","https://github.com/Trusted-AI/AIF360

http://aif360.mybluemix.net/"
147,Ethics & Algorithms Toolkit (beta),,,Planning and design; Planning and design; Performance evaluation,Beneficence; Non-Maleficence; Justice,Social Good; Responsibility; Prevention; Safety; Fairness; Trade-offs,Does not apply,4,Public; NGO; Academic,Guide; Resource Compendium; Website; Tool Compendium,Does not apply,https://ethicstoolkit.ai/,2018,"David Anderson, Joy Bonaguro, Miriam McKinney, Andrew Nicklin, Jane Wiseman",
148,AI Explainability 360 (AIX360),One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Multi-class Classification; Natural Language Processing; Computer Vision; Regression,"4,5",Private,Article; Code; Website,Python,https://doi.org/10.48550/arXiv.1909.03012,2019,"Vijay Arya, Rachel K. E. Bellamy, Pin-Yu Chen, Amit Dhurandhar, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Q. Vera Liao, Ronny Luss, Aleksandra Mojsilović, Sami Mourad, Pablo Pedemonte, Ramya Raghavendra, John Richards, Prasanna Sattigeri, Karthikeyan Shanmugam, Moninder Singh, Kush R. Varshney, Dennis Wei, Yunfeng Zhang, IBM","https://github.com/Trusted-AI/AIX360

http://aix360.mybluemix.net/"
149,AI Ethics Lab,,,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Beneficence; Non-Maleficence; Non-Maleficence; Justice; Justice; Non-Maleficence; Governance,Social Good; Responsibility; Reliability; Auditability; Prevention,Does not apply,"4,7",Private,Website; Practical Framework; Tool Compendium,Does not apply,https://aiethicslab.com/,2018,AI Ethics Lab,"https://aiethicslab.com/the-box/

https://aiethicslab.com/big-picture

https://aiethicslab.com/pie-model"
150,Ethical OS,,,Planning and design; Planning and design,Non-Maleficence; Justice,Reliability; Safety; Prevention; Trade-offs,Does not apply,"4,4",NGO,Website; Tool Compendium; Guide; Checklist,Does not apply,https://ethicalos.org/,2018,"Omidyar Network, Institute for the Future","https://ethicalos.org/wp-content/uploads/2018/08/Ethical-OS-Toolkit-2.pdf

https://ethicalos.org/wp-content/uploads/2018/08/EthicalOS_Check-List_080618.pdf"
151,AI Ethics Tool Landscape,,,Planning and design; Planning and design; Planning and design,Non-Maleficence; Justice; Explicability,Accountability; Privacy; Security; Fairness; Explicability; Interpretability,Does not apply,4,Academic,Website; Tool Compendium,Does not apply,https://edwinwenink.github.io/ai-ethics-tool-landscape/,2021,Edwin Wenink,https://github.com/EdwinWenink/ai-ethics-tool-landscape
152,Agile Ethics for AI (HAI),,,Planning and design,Beneficence,Social Good; Well-being; Responsibility,Does not apply,"4,5",NGO; Academic,Website; Resource Compendium; Tool Compendium; Guide,Does not apply,https://trello.com/b/SarLFYOd/agile-ethics-for-ai-hai,2018,"Catalina Butnaru, David Benrimoh, Andreas Theodorou","http://web.archive.org/web/20190719014913/https://humansinai.com/wp-content/uploads/2018/01/Humans-in-AI-Design-process-for-AI.pdf

http://web.archive.org/web/20181127125034/https://humansinai.com/"
153,Evaluate,,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Non-Maleficence,Auditability; Reliability,Regression; Binary Classification; Multi-class Classification; Natural Language Processing; Computer Vision,4,Private,Code; Website,Python,https://github.com/huggingface/evaluate,2020,Hugging Face Community,"https://huggingface.co/docs/evaluate/index

https://huggingface.co/evaluate-metric"
154,FAT Forensics,"FAT Forensics: A Python Toolbox for Implementing and Deploying Fairness, Accountability and Transparency Algorithms in Predictive Systems",,"Collection, understanding and preparation of data; Performance evaluation; Performance evaluation",Non-Maleficence; Justice; Explicability,Accountability; Reliability; Fairness; Explicability; Interpretability,Multi-class Classification; Computer Vision,4,Academic,Article; Code,Python,https://doi.org/10.21105/joss.01904,2019,"Kacper Sokol, Alexander Hepburn, Rafael Poyiadzi, Matthew Clifford, Raul Santos-Rodriguez, Peter Flach","https://github.com/fat-forensics/fat-forensics

https://fat-forensics.org/

https://github.com/bethgelab/foolbox

https://github.com/cleverhans-lab/cleverhans"
155,Triage,,,"Collection, understanding and preparation of data; Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Beneficence; Non-Maleficence; Justice; Justice,Social Good; Responsibility; Quality Data; Reliability; Fairness; Accountability,Regression; Binary Classification; Multi-class Classification,"4,5",Academic,Code,Python,https://github.com/dssg/triage,2017,"Data Science for Social Good, Carnegie Mellon University",https://dssg.github.io/triage/
156,DiCE ,Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations,,Performance evaluation,Explicability,Explicability; Interpretability,Regression; Binary Classification; Multi-class Classification,"4,5",Private; Academic,Article; Code,Python,https://doi.org/10.1145/3351095.3372850,2020,"Ramaravind Kommiya Mothilal, Amit Sharma, Chenhao Tan","https://github.com/interpretml/DiCE

http://interpret.ml/DiCE/index.html"
157,Fairness Measures,,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Justice,Fairness; Auditability,Binary Classification,"3,6",Academic,Code; Dataset; Website,Python,https://fairnessmeasures.github.io/,2017,"Meike Zehlike, Carlos Castillo, Francesco Bonchi, Mohamed Megahed, Lin Yang, Ricardo Baeza-Yates, Sara Hajian",https://github.com/FairnessMeasures/fairness-measures-code
158,A comparative study of fairness-enhancing interventions in machine learning,,,Performance evaluation,Justice,Fairness; Auditability,Binary Classification,"3,8",Academic,Article; Code; Examples,Python,https://doi.org/10.48550/arXiv.1802.04422,2018,"Sorelle A. Friedler, Carlos Scheidegger, Suresh Venkatasubramanian, Sonam Choudhary, Evan P. Hamilton, Derek Roth",https://github.com/algofairness/fairness-comparison
159,Themis ML,Themis ML:  A Fairness-aware Machine Learning Interface for End-to-end Discrimination Discovery and Mitigation,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Justice; Justice; Justice,Fairness; Auditability,Binary Classification,"3,9",Academic,Article; Code; Dataset; Examples,Python,https://doi.org/10.48550/arXiv.1710.06921,2017,Niels Bantilan,https://github.com/cosmicBboy/themis-ml
160,Fairness Indicators,,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Justice,Fairness; Auditability,Binary Classification; Multi-class Classification,"4,3",Private; Academic,Code; Examples; Case Studies,Python,https://github.com/tensorflow/fairness-indicators,2019,"TensorFlow, Google",https://github.com/tensorflow/fairness-indicators/blob/master/g3doc/guide/guidance.md
161,UnBias Fairness Toolkit,,,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data",Beneficence; Autonomy; Justice,Social Good; Well-being; Responsibility; Agency; Fairness; Prevention,Does not apply,"4,1",Academic; NGO,Guide; Practical Framework; Tool Compendium,Does not apply,https://doi.org/10.5281/zenodo.2667808,2018,"Giles Lane, Alice Angus, Alex Murdoch",https://unbias.wp.horizon.ac.uk/fairness-toolkit/
162,ELI5,,,Performance evaluation,Explicability,Explicability; Interpretability,Regression; Binary Classification; Multi-class Classification; Computer Vision,"4,2",Academic,Code,Python,https://github.com/eli5-org/eli5,2017,"Mikhail Korobov, Konstantin Lopuhin",https://eli5.readthedocs.io/en/latest/
163,inFairness,inFairness: Individual Fairness for Machine Learning,,Model setup and training; Performance evaluation,Justice; Justice,Fairness,Binary Classification; Multi-class Classification; Natural Language Processing,"4,3",Private,Code,Python,https://github.com/IBM/inFairness,2022,"Mikhail Yurochkin, Mayank Agarwal, Aldo Pareja, Onkar Bhardwaj","https://ibm.github.io/inFairness/index.html

https://fairbert.vizhub.ai/"
164,FairSight,FairSight: Visual analytics for fairness in decision making,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Justice; Justice; Explicability,Fairness; Auditability; Explicability,Binary Classification; Multi-class Classification,"4,4",Academic,Code; Program; Article,Python; JavaScript,https://doi.org/10.48550/arXiv.1908.00176,2019,"Yongsu Ahn, Yu-Ru Lin",https://github.com/ayong8/FairSight
165,Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings,Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings,,"Collection, understanding and preparation of data",Justice,Fairness,Natural Language Processing,4,Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1607.06520,2016,"Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, Adam Kalai",https://github.com/tolga-b/debiaswe
166,DEBIE: A General Framework for Implicit and Explicit Debiasing of Distributional Word Vector Spaces,DEBIE: A General Framework for Implicit and Explicit Debiasing of Distributional Word Vector Spaces,,"Collection, understanding and preparation of data",Justice,Fairness,Natural Language Processing,"4,1",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1909.06092,2019,"Anne Lauscher, Goran Glavaš, Simone Paolo Ponzetto, Ivan Vulić",https://github.com/anlausch/DEBIE
167,ML Fairness Gym,,,Planning and design; Deployment and monitoring,Justice; Non-Maleficence,Fairness; Prevention; Reliability; Safety,Binary Classification,"4,2",Academic,Code; Examples,Python,https://github.com/google/ml-fairness-gym,2019,ML Fairness Gym Team,
168,Fairness in Machine Learning,,,Model setup and training; Performance evaluation,Justice; Justice,Fairness; Auditability,Binary Classification,4,Academic,Code; Examples,Python,https://github.com/equialgo/fairness-in-ml,2018,"Henk Griffioen, Stijn Tonk, Rogier van der Geer","https://godatadriven.com/blog/towards-fairness-in-ml-with-adversarial-networks/

https://godatadriven.com/blog/fairness-in-machine-learning-with-pytorch/"
169,Black Box Auditing,Auditing Black-box Models for Indirect Influence,,Performance evaluation; Performance evaluation,Justice; Explicability,Auditability; Fairness; Interpretability,Binary Classification,4,Academic,Code; Examples; Dataset; Article,Python,https://doi.org/10.48550/arXiv.1602.07043,2016,"Philip Adler, Casey Falk, Sorelle A. Friedler, Gabriel Rybeck, Carlos Scheidegger, Brandon Smith, Suresh Venkatasubramanian",https://github.com/algofairness/BlackBoxAuditing
170,LinkedIn Fairness Toolkit (LiFT),LiFT: A Scalable Framework for Measuring Fairness in ML Applications,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Justice,Fairness; Auditability,Binary Classification,"4,2",Private,Code; Article,Scala; Spark,https://doi.org/10.48550/arXiv.2008.07433,2020,"Sriram Vasudevan, Krishnaram Kenthapadi",https://github.com/linkedin/LiFT
171,Responsibly Toolkit,Responsibly: Toolkit for Auditing and Mitigating Bias and Fairness of Machine Learning Systems,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Justice,Fairness; Auditability,Binary Classification; Natural Language Processing,"4,1",Academic,Code; Dataset,Python,https://github.com/ResponsiblyAI/responsibly,2018,Shlomi Hod,https://docs.responsibly.ai/
172,CERTIFAI,CERTIFAI: A Common Framework to Provide Explanations and Analyse the Fairness and Robustness of Black-box Models,,Model setup and training; Performance evaluation; Performance evaluation,Justice; Explicability; Non-Maleficence,Fairness; Explicability; Interpretability; Security; Reliability,Binary Classification; Multi-class Classification,"4,1",Academic,Code; Article,Python,https://doi.org/10.1145/3375627.3375812,2020,"Shubham Sharma, Jette Henderson, Joydeep Ghosh",https://github.com/Ighina/CERTIFAI
173,OmniXAI,OmniXAI: A Library for Explainable AI,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Explicability; Explicability; Explicability; Explicability,Explicability; Interpretability,Regression; Binary Classification; Natural Language Processing; Computer Vision; Multi-class Classification,"4,6",Private,Code; Article,Python,https://doi.org/10.48550/arXiv.2206.01612,2022,"Wenzhuo Yang, Hung Le, Tanmay Laud, Silvio Savarese, Steven C.H. Hoi",https://github.com/salesforce/OmniXAI
174,XAI - An eXplainability toolbox for machine learning,,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Explicability; Explicability; Explicability,Explicability; Interpretability,Binary Classification,"4,2",Academic,Code; Article; Resource Compendium,Python,https://github.com/EthicalML/xai,2019,The Institute for Ethical AI & Machine Learning,"https://ethical.institute/

https://github.com/EthicalML/awesome-production-machine-learning"
175,iml,iml: An R package for Interpretable Machine Learning,,Performance evaluation,Explicability,Interpretability,Binary Classification,4,Academic,Code; Article,R,https://doi.org/10.21105/joss.00786,2018,"Christoph Molnar, Giuseppe Casalicchio, Bernd Bischl","https://github.com/christophM/iml

https://christophm.github.io/interpretable-ml-book/agnostic.html"
176,Interpret Text,Interpret Text - Alpha Release,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Explicability; Explicability; Explicability,Explicability; Interpretability,Natural Language Processing,"4,4",Private,Code,Python,https://github.com/interpretml/interpret-text,2019,"InterpretML Community, Microsoft",
177,iBreakDown,Explanations of model predictions with live and breakDown packages,,Performance evaluation,Explicability,Explicability; Interpretability,Binary Classification; Regression,"4,3",Academic,Code; Article,R,https://doi.org/10.32614/RJ-2018-072,2018,"Mateusz Staniak, Przemysław Biecek","https://github.com/ModelOriented/iBreakDown

https://modeloriented.github.io/iBreakDown/

https://ema.drwhy.ai/breakDown.html"
178,Anchor,Anchors: High-Precision Model-Agnostic Explanations,,Performance evaluation,Explicability,Explicability; Interpretability,Binary Classification; Natural Language Processing,"4,1",Academic,Code; Article,Python,https://doi.org/10.1609/aaai.v32i1.11491,2018,"Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin",https://github.com/marcotcr/anchor
179,SHAP,A Unified Approach to Interpreting Model Predictions,,Performance evaluation,Explicability,Explicability; Interpretability,Computer Vision; Natural Language Processing; Binary Classification; Regression; Multi-class Classification,"4,6",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1705.07874,2017,"Scott Lundberg, Su-In Lee",https://github.com/slundberg/shap
180,Captum,Captum: A unified and generic model interpretability library for PyTorch,,Performance evaluation,Explicability,Explicability; Interpretability,Regression; Binary Classification; Computer Vision; Natural Language Processing; Multi-class Classification,"4,6",Private,Code; Article,Python,https://doi.org/10.48550/arXiv.2009.07896,2020,"Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Bilal Alsallakh, Jonathan Reynolds, Alexander Melnikov, Natalia Kliushkina, Carlos Araya, Siqi Yan, Orion Reblitz-Richardson",https://github.com/pytorch/captum
181,explabox,,,"Collection, understanding and preparation of data; Performance evaluation",Non-Maleficence; Explicability,Explicability; Interpretability; Safety,Binary Classification; Multi-class Classification; Natural Language Processing,"4,4",Academic,Code,Python,https://github.com/MarcelRobeer/explabox,2022,Marcel Robeer,https://explabox.readthedocs.io/en/latest/index.html
182,DeepVis Toolbox,Understanding Neural Networks Through Deep Visualization,,Model setup and training; Performance evaluation,Explicability; Explicability,Interpretability; Explicability,Computer Vision,4,Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1506.06579,2015,"Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, Hod Lipson","https://github.com/yosinski/deep-visualization-toolbox

https://yosinski.com/deepvis

https://youtu.be/AgkfIQ4IGaM"
183,GEBI,Towards explainable classifiers using the counterfactual approach - global explanations for discovering bias in data,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Explicability,Fairness; Explicability; Interpretability,Computer Vision,"4,1",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.2005.02269,2020,"Agnieszka Mikołajczyk, Michał Grochowski, Arkadiusz Kwasigroch",https://github.com/AgaMiko/GEBI
184,iNNvestigate,iNNvestigate Neural Networks!,,Performance evaluation,Explicability,Interpretability,Computer Vision,"4,2",Academic,Code; Article,Python,http://jmlr.org/papers/v20/18-540.html,2019,"Maximilian Alber, Sebastian Lapuschkin, Philipp Seegerer, Miriam Hägele, Kristof T. Schütt, Grégoire Montavon, Wojciech Samek, Klaus-Robert Müller, Sven Dähne, Pieter-Jan Kindermans",https://github.com/albermax/innvestigate
185,TreeInterpreter,,,Performance evaluation,Explicability,Interpretability,Regression; Binary Classification,"3,6",Academic,Code; Examples,Python,https://github.com/andosa/treeinterpreter,2016,"Ando Saabas, Micah Smith, Dennis Collaris, Julian Gilbey, Mickey Shnaiderman, Li Jiangchun, Marc Tollin","http://blog.datadive.net/interpreting-random-forests/

http://blog.datadive.net/random-forest-interpretation-with-scikit-learn/"
186,Skater,,,Performance evaluation,Explicability,Explicability; Interpretability,Computer Vision; Natural Language Processing; Binary Classification; Regression,4,Private,Code,Python,https://github.com/oracle/skater,2018,Oracle,http://web.archive.org/web/20210927095651/https://oracle.github.io/Skater/overview.html
187,7010-2020 - IEEE Recommended Practice for Assessing the Impact of Autonomous and Intelligent Systems on Human Well-Being,7010-2020 - IEEE Recommended Practice for Assessing the Impact of Autonomous and Intelligent Systems on Human Well-Being,,Businness and problem understanding; Planning and design,Beneficence; Beneficence,Well-being; Social Good; Responsibility,Does not apply,4,Private; Public,Standard; Guide,Does not apply,https://doi.org/10.1109/IEEESTD.2020.9084219,2020,Institute of Electrical and Electronics Engineers (IEEE),https://www.researchgate.net/publication/344288261_IEEE_P7010-2020_Standard_Use_Cases_in_Ethical_Impact_on_Human_Wellbeing_Studies
188,FairVis,FairVis: Visual Analytics for Discovering Intersectional Bias in Machine Learning,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Justice,Fairness; Auditability,Binary Classification,"4,3",Academic,Article; Program,JavaScript,https://doi.org/10.48550/arXiv.1904.05419,2019,"Ángel Alexander Cabrera, Will Epperson, Fred Hohman, Minsuk Kahng, Jamie Morgenstern, Duen Horng Chau",https://github.com/poloclub/FairVis
189,explAIner,explAIner: A Visual Analytics Framework for Interactive and Explainable Machine Learning,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Regression; Binary Classification; Natural Language Processing; Computer Vision,"4,4",Private; Academic,Article; Code,TypeScript,https://doi.org/10.48550/arXiv.1908.00087,2019,"Thilo Spinner, Udo Schlegel, Hanna Schäfer, Mennatallah El-Assady","https://explainer.ai

https://github.com/dbvis-ukon/explainer"
190,RetainVis,RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records,,"Collection, understanding and preparation of data; Performance evaluation",Explicability; Explicability,Interpretability,Binary Classification,"4,1",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1805.10724,2018,"Bum Chul Kwon, Min-Je Choi, Joanne Taery Kim, Edward Choi, Young Bin Kim, Soonwook Kwon, Jimeng Sun, Jaegul Choo",https://github.com/minjechoi/RetainVis
191,Interpretable Machine Learning: A Guide for Making Black Box Models Explainable (First Edition),,,"Planning and design; Collection, understanding and preparation of data; Performance evaluation",Explicability; Explicability; Explicability,Explicability; Interpretability,Does not apply,"4,2",Academic,Book; Examples; Dataset; Guide,Python; R,https://originalstatic.aminer.cn/misc/pdf/Molnar-interpretable-machine-learning_compressed.pdf,2019,Christoph Molnar,https://christophm.github.io/interpretable-ml-book/
192,GDPR Toolkit,,,"Planning and design; Collection, understanding and preparation of data",Non-Maleficence; Non-Maleficence; Governance,Security; Safety; Privacy; Quality Data,Does not apply,"4,1",Public,Website; Tool Compendium; Resource Compendium,Does not apply,https://www.cnil.fr/en/gdpr-toolkit,2019,Commission Nationale de l'Informatique et des Libertés (CNIL),"https://gdpr.eu/data-protection-impact-assessment-template

https://commission.europa.eu/law/law-topic/data-protection/reform/rules-business-and-organisations/obligations/when-data-protection-impact-assessment-dpia-required_en

https://www.cnil.fr/en/privacy-impact-assessment-pia

https://gdpr.eu

https://link.springer.com/chapter/10.1007/978-3-030-55196-4_1"
193,DeepLIFT,Learning Important Features Through Propagating Activation Differences,,Performance evaluation,Explicability,Explicability; Interpretability,Regression; Computer Vision; Multi-class Classification; Binary Classification,4,Academic,Article; Code,Python,https://doi.org/10.48550/arXiv.1704.02685,2017,"Avanti Shrikumar, Peyton Greenside, Anshul Kundaje","https://github.com/kundajelab/deeplift

https://www.youtube.com/playlist?list=PLJLjQOkqSRTP3cLB2cOOi_bQFw6KPGKML"
194,RuleMatrix,RuleMatrix: Visualizing and Understanding Classifiers with Rules,,Model setup and training; Performance evaluation,Explicability; Explicability,Transparency; Explicability; Interpretability,Binary Classification; Multi-class Classification,"4,2",Academic,Article; Code,Python; JavaScript,https://doi.org/10.48550/arXiv.1807.06228,2018,"Yao Ming, Huamin Qu, Enrico Bertini",https://github.com/rulematrix/rule-matrix-py
195,DeepExplain,Towards better understanding of gradient-based attribution methods for Deep Neural Networks,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Computer Vision; Binary Classification; Multi-class Classification; Natural Language Processing,"4,3",Academic,Article; Code,Python,https://doi.org/10.48550/arXiv.1711.06104,2018,"Marco Ancona, Enea Ceolini, Cengiz Öztireli, Markus Gross",https://github.com/marcoancona/DeepExplain
196,PiML,PiML: An integrated Python toolbox for interpretable machine learning,,"Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Non-Maleficence; Justice; Justice; Explicability,Explicability; Interpretability; Fairness; Reliability,Regression; Binary Classification; Multi-class Classification,"4,5",Academic,Article; Code,Python,https://arxiv.org/abs/2305.04214v1,2022,"Agus Sudjianto, Aijun Zhang, Zebin Yang, Yu Su, Ningzhou Zeng","https://github.com/SelfExplainML/PiML-Toolbox

https://selfexplainml.github.io/PiML-Toolbox/_build/html/index.html"
197,Concrete ML,Concrete ML: a Privacy-Preserving Machine Learning Library using Fully Homomorphic Encryption for Data Scientists,,Model setup and training; Performance evaluation,Non-Maleficence; Non-Maleficence,Privacy; Security; Reliability,Computer Vision; Binary Classification; Regression; Multi-class Classification,"4,5",Private,Code; Website,Python,https://github.com/zama-ai/concrete-ml,2022,"Arthur Meyre, Benoit Chevallier-Mames, Jordan Frery, Andrei Stoian, Roman Bredehoft, Luis Montero, Celia Kherfallah",https://docs.zama.ai/concrete-ml
198,MPyC,MPyC: Multiparty Computation in Python,,"Collection, understanding and preparation of data; Model setup and training",Non-Maleficence; Non-Maleficence,Security; Privacy,Does not apply,4,Academic,Code,Python,https://github.com/lschoe/mpyc,2018,Berry Schoenmakers,https://mpyc.readthedocs.io/en/latest/
199,Assessment List for Trustworthy Artificial Intelligence (ALTAI),,,Businness and problem understanding; Planning and design,Beneficence; Beneficence; Governance,Responsibility; Social Good; Well-being; Trust,Does not apply,4,Private; Public,Website; Practical Framework; Principles,Does not apply,https://futurium.ec.europa.eu/en/european-ai-alliance/pages/welcome-altai-portal,2020,"European AI Alliance, AI HLEG",https://altai.insight-centre.org/
200,capAI - A Procedure for Conducting Conformity Assessment of AI Systems in Line with the EU Artificial Intelligence Act,capAI - A Procedure for Conducting Conformity Assessment of AI Systems in Line with the EU Artificial Intelligence Act,,Businness and problem understanding; Planning and design,Beneficence; Non-Maleficence; Governance,Responsibility; Social Good; Well-being; Trust; Accountability,Does not apply,"4,2",Academic,Article; Guide; Resource Compendium,Does not apply,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4064091,2022,"Luciano Floridi, Matthias Holweg, Mariarosaria Taddeo, Javier Amaya Silva, Jakob Mökander, Yuni Wen",https://artificialintelligenceact.eu/assessment/
201,RES,RES: A Robust Framework for Guiding Visual Explanation,,Performance evaluation,Explicability,Explicability; Interpretability,Computer Vision,4,Academic,Code; Article,Python,https://doi.org/10.1145/3534678.3539419,2022,"Yuyang Gao, Tong Steven Sun, Guangji Bai, Siyi Gu, Sungsoo Ray Hong, Zhao Liang","https://github.com/YuyangGao/RES

https://www.researchgate.net/publication/361204389_RES_A_Robust_Framework_for_Guiding_Visual_Explanation"
202,PyTorch library for CAM methods,Advanced AI explainability for PyTorch,,Performance evaluation,Explicability,Explicability; Interpretability,Computer Vision,"4,3",Academic,Code; Examples,Python,https://github.com/jacobgil/pytorch-grad-cam,2021,"Jacob Gildenblat, Contributors",https://blog.aiensured.com/gradcam-plus-plus/
203,TorchCAM: class activation explorer,,,Performance evaluation,Explicability,Explicability; Interpretability,Computer Vision,"4,2",Academic,Code; Examples,Python,https://github.com/frgfm/torch-cam,2020,François-Guillaume Fernandez,https://frgfm.github.io/torch-cam/
204,Diffprivlib,Diffprivlib: The IBM Differential Privacy Library,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Non-Maleficence; Non-Maleficence; Non-Maleficence,Privacy; Security; Reliability,Binary Classification; Clustering; Dimensionality Reduction; Regression,"4,3",Private,Article; Code,Python,https://doi.org/10.48550/arXiv.1907.02444,2019,"Naoise Holohan, Stefano Braghin, Pól Mac Aonghusa, Killian Levacher",https://github.com/IBM/differential-privacy-library
205,Artificial Intelligence Act - EU,REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE (ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION LEGISLATIVE ACTS,,Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Justice; Governance,Human Rights; Responsibility; Social Good; Well-being; Trust; Reliability; Auditability,Does not apply,Does not apply,Public,Law,Does not apply,https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206,2021,European Comission,https://link.springer.com/article/10.1007/s11023-021-09577-4
206,Activation Maximization,,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Computer Vision,"3,8",Academic,Code,Python,https://github.com/Nguyen-Hoa/Activation-Maximization,2020,Nguyen Hoa,https://doi.org/10.48550/arXiv.1506.06579
207,Keras-Vis,Keras Visualization Toolkit,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Computer Vision,"4,1",Academic,Code,Python,https://github.com/raghakot/keras-vis,2017,"Raghavendra Kotikalapudi, Contributors",
208,The LRP Toolbox for Artificial Neural Networks,,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Computer Vision; Multi-class Classification; Natural Language Processing,"4,3",Academic,Code; Article,Python; MATLAB,https://jmlr.org/papers/v17/15-618.html,2016,"Sebastian Lapuschkin, Alexander Binder, Grégoire Montavon, Klaus-Robert Müller, Wojciech Samek","https://github.com/sebastian-lapuschkin/lrp_toolbox

https://lrpserver.hhi.fraunhofer.de/

https://github.com/sebastian-lapuschkin/lrp_toolbox/blob/master/doc/manual/manual.pdf"
209,"Zennit, CoRelAy, and ViRelAy","Software for Dataset-wide XAI: From Local Explanations to Global Insights with Zennit, CoRelAy, and ViRelAy",,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Explicability; Explicability; Explicability,Explicability; Interpretability,Computer Vision; Clustering,"4,3",Academic,Code; Article; Program,Python,https://doi.org/10.48550/arXiv.2106.13200,2021,"Christopher J. Anders, David Neumann, Wojciech Samek, Klaus-Robert Müller, Sebastian Lapuschkin","https://github.com/chr5tphr/zennit

https://github.com/virelay/corelay

https://github.com/virelay/virelay"
210,Examining the Black Box: Tools for assessing algorithmic systems,,,Businness and problem understanding; Planning and design,Non-Maleficence; Justice,Privacy; Reliability; Auditability; Fairness; Prevention,Does not apply,4,Public,Report; Resource Compendium; Guide,Does not apply,https://www.adalovelaceinstitute.org/report/examining-the-black-box-tools-for-assessing-algorithmic-systems/,2020,"Ada Lovelace Institute, DataKind UK",
211,The algorithm audit: Scoring the algorithms that score us,The algorithm audit: Scoring the algorithms that score us,,Businness and problem understanding; Planning and design,Non-Maleficence; Justice,Prevention; Reliability; Privacy; Auditability,Does not apply,Does not apply,Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1177/2053951720983865,2021,"Shea Brown, Jovana Davidovic, Ali Hasan ",
212,Guidance on the AI auditing framework,,,"Planning and design; Collection, understanding and preparation of data; Collection, understanding and preparation of data",Beneficence; Non-Maleficence; Justice; Governance,Accountability; Transparency; Reliability; Security; Privacy; Safety; Fairness,Does not apply,4,Public,Guide; Theoretical Framework; Resource Compendium; Examples,Does not apply,https://ico.org.uk/media/2617219/guidance-on-the-ai-auditing-framework-draft-for-consultation.pdf,2020,Information Commissioner's Office (ICO),
213,"Artificial Intelligence: detailed guide and resources for businesses in the public, private and third sectors",,,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data",Beneficence; Non-Maleficence; Justice,Human Rights; Social Good; Privacy; Safety; Auditability; Prevention,Does not apply,"4,2",Public,Website; Guide; Resource Compendium,Does not apply,https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/,2022,Information Commissioner's Office (ICO),"https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/

https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/

https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/ai-and-data-protection-risk-toolkit/

https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/toolkit-for-organisations-considering-using-data-analytics/"
214,BertViz,A Multiscale Visualization of Attention in the Transformer Model,,Performance evaluation,Explicability,Explicability; Interpretability,Natural Language Processing,"4,2",Academic,Article; Code,Python,https://doi.org/10.18653/v1/P19-3007,2019,Jesse Vig,https://github.com/jessevig/bertviz
215,tf-explain,tf-explain: Interpretability Methods for tf.keras models with TensorFlow 2.x,,Model setup and training; Performance evaluation,Explicability; Explicability,Interpretability,Computer Vision,"4,1",Academic,Code,Python,https://doi.org/10.5281/zenodo.5711704,2021,Raphael Meudec,https://github.com/sicara/tf-explain
216,InterpretDL,InterpretDL: Explaining Deep Models in PaddlePaddle,,"Collection, understanding and preparation of data; Performance evaluation",Explicability; Explicability,Interpretability,Computer Vision; Natural Language Processing,"4,3",Academic,Article; Code,Python,http://jmlr.org/papers/v23/21-0738.html,2022,"Xuhong Li, Haoyi Xiong, Xingjian Li, Xuanyu Wu, Zeyu Chen, Dejing Dou",https://github.com/PaddlePaddle/InterpretDL
217,Mondrian,,,"Collection, understanding and preparation of data",Non-Maleficence,Security; Privacy; Safety,Does not apply,"3,9",Academic,Code,Python; Java,https://github.com/qiyuangong/Mondrian,2017,"Qiyuan Gong, Liu Kun","https://ftp.cs.wisc.edu/pub/techreports/2005/TR1521.pdf

http://cs.utdallas.edu/dspl/cgi-bin/toolbox/index.php?go=home

https://github.com/arx-deidentifier/arx"
218,K-Anonymity,,,"Collection, understanding and preparation of data",Non-Maleficence,Security; Privacy; Safety,Does not apply,"3,9",Academic,Code; Examples,Python,https://github.com/Nuclearstar/K-Anonymity,2019,Nithin Prabhu,"https://github.com/glassonion1/anonypy

https://github.com/leo-mazz/crowds"
219,Anonymization,,,"Collection, understanding and preparation of data",Non-Maleficence,Security; Privacy; Safety,Does not apply,"3,9",Private,Code,Python,https://github.com/Smile-SA/anonymization,2019,Smile - Open Source Solutions,
220,CryptoDL,,,Model setup and training,Non-Maleficence,Security; Privacy; Safety,Regression; Multi-class Classification; Computer Vision; Natural Language Processing,4,Academic,Code,C++,https://github.com/inspire-lab/CryptoDL,2020,INSPIRE Lab,
221,SDV (Synthetic Data Vault),The Synthetic Data Vault,,"Collection, understanding and preparation of data",Non-Maleficence,Security; Privacy; Safety; Reliability,Does not apply,"4,5",Academic,Article; Code,Python,https://doi.org/10.1109/DSAA.2016.49,2016,"Neha Patki, Roy Wedge, Kalyan Veeramachaneni","https://github.com/sdv-dev/SDV

https://dai.lids.mit.edu/wp-content/uploads/2018/03/SDV.pdf"
222,VisioRed,Interactive UI Tool for Interpretable Time Series Forecasting called VisioRed,,Performance evaluation,Explicability,Interpretability,Regression; Multi-class Classification; Time Series,"4,1",Academic,Program,Python,https://github.com/intelligence-csd-auth-gr/Interpretable-Predictive-Maintenance,2021,"Spyridon Paraschos, Ioannis Mollas, Grigorios Tsoumakas, Nick Bassiliades",https://intelligence.csd.auth.gr/wp-content/uploads/2021/03/Elevating_Interpretable_Predictive_Maintenance_through_VisioRed_and_iPCA.pdf
223,The TAILOR Handbook of Trustworthy AI,,,Businness and problem understanding; Businness and problem understanding; Planning and design; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Social Good; Trust; Responsibility; Sustainability; Security; Privacy; Safety; Quality Data; Reliability; Agency; Fairness; Auditability; Transparency; Explicability; Interpretability,Does not apply,"4,3",Public; Academic,Book; Resource Compendium; Tool Compendium,Does not apply,http://tailor.isti.cnr.it/handbookTAI/TAILOR.html,2022,"Umberto Straccia, Francesca Pratesi, Riccardo Albertoni, Tristan Allard, Guilherme Alves, Alejandra Bringas Colmenarejo, Stefan Buijsman, Pablo A. M. Casares, Sara Colantonio, Miguel Couceiro, Santiago Escobar, Gabriel Gonzalez-Castañé, Riccardo Guidotti, Fredrik Heintz, Jose Hernandez-Orallo, Sietze Kuilman, Karima Makhlouf, Fernando Martinez-Plumed, Anna Monreale, Roberto Pellungrini, Francesca Pratesi, Resmi Ramachandran Pillai, Andrea Rossi, Marie-Christine Rousset, Salvatore Ruggieri, Luciano C. Siebert, Piotr Skrzypczyński, Jerzy Stefanowski, Barry O'Sullivan, Andrea Visentin, Arkady Zgonnikov, Sami Zhioua",
224,OpenXAI,OpenXAI: Towards a Transparent Evaluation of Model Explanations,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Non-Maleficence; Justice; Explicability,Explicability; Interpretability; Fairness; Reproducibility; Transparency,Binary Classification,"4,1",Academic,Code; Article; Dataset,Python,https://doi.org/10.48550/arXiv.2206.11104,2022,"Chirag Agarwal, Satyapriya Krishna, Eshika Saxena, Martin Pawelczyk, Nari Johnson, Isha Puri, Marinka Zitnik, Himabindu Lakkaraju","https://github.com/AI4LIFE-GROUP/OpenXAI

https://open-xai.github.io/"
225,Xplique,Xplique: A Deep Learning Explainability Toolbox,,Performance evaluation,Explicability,Explicability; Interpretability,Computer Vision; Regression; Multi-class Classification,"4,2",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.2206.04394,2022,"Thomas Fel, Lucas Hervier, David Vigouroux, Antonin Poche, Justin Plakoo, Remi Cadene, Mathieu Chalvidal, Julien Colin, Thibaut Boissin, Louis Bethune, Agustin Picard, Claire Nicodeme, Laurent Gardes, Gregory Flandin, Thomas Serre",https://github.com/deel-ai/xplique
226,TorchEsegeta,TorchEsegeta: Framework for Interpretability and Explainability of Image-based Deep Learning Models,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Computer Vision; Multi-class Classification,"4,1",Academic,Code; Article,Python,https://doi.org/10.3390/app12041834,2022,"Soumick Chatterjee, Arnab Das, Chirag Mandal, Budhaditya Mukhopadhyay, Manish Vipinraj, Aniruddh Shukla, Rajatha Nagaraja Rao, Chompunuch Sarasaen, Oliver Speck, Andreas Nürnberger",https://github.com/soumickmj/TorchEsegeta
227,NeuroCartography,NeuroCartography: Scalable Automatic Visual Summarization of Concepts in Deep Neural Networks,,Performance evaluation,Explicability,Interpretability,Computer Vision; Multi-class Classification,"4,3",Academic,Code; Program; Article,Python,https://doi.org/10.48550/arXiv.2108.12931,2021,"Haekyu Park, Nilaksh Das, Rahul Duggal, Austin P. Wright, Omar Shaikh, Fred Hohman, Duen Horng Chau",https://github.com/poloclub/neuro-cartography
228,explainX,explainX: Explainable AI Framework for Data Scientists,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Explicability,Interpretability; Explicability; Fairness,Binary Classification; Regression; Multi-class Classification,"4,3",Academic,Code,Python,https://github.com/explainX/explainx,2020,"Ali Al-Ebrahim, Raheel Ahmad, Muddassar Sharif, Tawab Shakeel, Debarshi Chanda","https://github.com/explainX/Visual-Counterfactuals

https://github.com/explainX/Surrogate-Rule-Exploration-Method"
229,imbalanced-learn,Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning,,"Collection, understanding and preparation of data; Collection, understanding and preparation of data",Justice; Non-Maleficence,Fairness; Quality Data,Binary Classification; Multi-class Classification,"4,5",Academic,Code; Article,Python,https://jmlr.org/papers/v18/16-365.html,2017,"Guillaume Lemaitre, Fernando Nogueira, Christos K. Aridas","https://github.com/scikit-learn-contrib/imbalanced-learn

https://imbalanced-learn.org/stable/"
230,The Aletheia Framework,,,Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Justice; Governance,Social Good; Well-being; Responsibility; Trust; Reliability; Transparency; Accountability; Fairness,Does not apply,4,Private,Website; Resource Compendium; Tool Compendium; Practical Framework,Does not apply,https://www.rolls-royce.com/innovation/the-aletheia-framework.aspx,2021,Rolls-Royce,https://www.rolls-royce.com/media/press-releases/2020/14-12-2020-trustworthy-artificial-intelligence-rolls-royce-publishes-pioneering-bias-control.aspx
231,Artificial Intelligence Risk Management Framework,,,Businness and problem understanding; Businness and problem understanding; Planning and design,Beneficence; Non-Maleficence; Justice; Governance,Prevention; Reliability; Social Good; Responsibility; Sustainability; Trust; Fairness,Does not apply,"4,3",Public,Practical Framework; Playbook; Resource Compendium,Does not apply,https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF,2021,National Institute of Standards and Technology (NIST),"https://doi.org/10.6028/NIST.AI.100-1

https://airc.nist.gov/AI_RMF_Knowledge_Base/Playbook

https://www.nist.gov/itl/ai-risk-management-framework

https://www.nist.gov/video/introduction-nist-ai-risk-management-framework-ai-rmf-10-explainer-video"
232,Confronting Bias: BSA’s Framework to Build Trust in AI,,,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Beneficence; Beneficence; Non-Maleficence; Justice; Justice; Non-Maleficence,Social Good; Trust; Fairness; Auditability; Accountability,Does not apply,"4,3",Private,Practical Framework; Resource Compendium; Report,Does not apply,https://ai.bsa.org/confronting-bias-bsas-framework-to-build-trust-in-ai,2021,BSA - The Software Alliance,"https://ai.bsa.org/wp-content/uploads/2021/06/2021bsaaibias.pdf

https://ai.bsa.org/wp-content/uploads/2021/06/2021bsaaibiasframework.pdf"
233,Model Cards for Model Reporting,Model Cards for Model Reporting,,Performance evaluation; Deployment and monitoring,Explicability; Non-Maleficence,Transparency; Accountability; Traceability,Does not apply,"4,4",Private; Academic,Practical Framework; Article,Does not apply,https://doi.org/10.48550/arXiv.1810.03993,2018,"Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, Timnit Gebru","https://modelcards.withgoogle.com/about

https://www.tensorflow.org/responsible_ai/model_card_toolkit/guide

https://cloud.google.com/blog/products/ai-machine-learning/create-a-model-card-with-scikit-learn"
234,Datasheets for Datasets,Datasheets for Datasets,,"Collection, understanding and preparation of data; Deployment and monitoring",Non-Maleficence; Explicability,Transparency; Accountability; Traceability,Does not apply,"4,4",Private; Academic,Article; Practical Framework,Does not apply,https://doi.org/10.48550/arXiv.1803.09010,2018,"Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé III, Kate Crawford","https://www.overleaf.com/latex/templates/datasheet-for-dataset-template/ztkyvzddvxtd

https://github.com/AudreyBeard/Datasheets-for-Datasets-Template"
235,Synthetic Data Showcase,,,"Collection, understanding and preparation of data",Non-Maleficence,Security; Privacy; Safety; Reliability,Does not apply,"4,4",Private,Website; Code; Program,Rust; Python; TypeScript,https://github.com/microsoft/synthetic-data-showcase,2020,Microsoft,https://microsoft.github.io/synthetic-data-showcase/
236,G-PATE,G-PATE: Scalable Differentially Private Data Generator via Private Aggregation of Teacher Discriminators,,"Collection, understanding and preparation of data; Model setup and training",Non-Maleficence; Non-Maleficence,Security; Privacy; Safety; Reliability,Computer Vision,"4,1",Academic,Article; Code,Python,https://doi.org/10.48550/arXiv.1906.09338,2021,"Yunhui Long, Boxin Wang, Zhuolin Yang, Bhavya Kailkhura, Aston Zhang, Carl A. Gunter, Bo Li",https://github.com/AI-secure/G-PATE
237,CrypTen,CrypTen: Secure Multi-Party Computation Meets Machine Learning,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Non-Maleficence; Non-Maleficence; Non-Maleficence,Security; Privacy; Safety; Reliability,Computer Vision; Natural Language Processing; Multi-class Classification,"4,4",Private,Code; Article,Python,https://doi.org/10.48550/arXiv.2109.00984,2021,"Brian Knott, Shobha Venkataraman, Awni Hannun, Shubho Sengupta, Mark Ibrahim, Laurens van der Maaten",https://github.com/facebookresearch/CrypTen
238,CrypTFlow,CrypTFlow: Secure TensorFlow Inference,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Non-Maleficence; Non-Maleficence; Non-Maleficence,Security; Privacy; Safety; Reliability,Computer Vision; Multi-class Classification; Regression,"4,3",Private; Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1909.07814,2020,"Nishant Kumar, Mayank Rathee, Nishanth Chandran, Divya Gupta, Aseem Rastogi, Rahul Sharma","https://github.com/mpc-msri/EzPC

https://pratik-bhatu.medium.com/privacy-preserving-machine-learning-for-healthcare-using-cryptflow-cc6c379fbab7

https://youtu.be/53rxhEmDqQk"
239,Explaining Machine Learning Algorithms,,,Planning and design,Explicability,Explicability; Interpretability,Does not apply,"4,1",Academic,Website; Resource Compendium,Does not apply,https://explainableairesearch.github.io/,2022,Avinash Bhat,
240,Bias Scan Tool,,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Justice,Fairness; Auditability,Binary Classification,4,NGO,Website; Code,Python,https://www.algorithmaudit.eu/bias_scan/,2022,NGO Algorithm Audit,"https://github.com/NGO-Algorithm-Audit/Bias_scan

https://github.com/NGO-Algorithm-Audit/Bias_scan/blob/master/Technical_documentation_bias_scan.pdf"
241,ExplainerDashboard,,,Performance evaluation,Explicability,Explicability; Interpretability,Regression; Binary Classification; Multi-class Classification,"4,4",Academic,Code,Python,https://doi.org/10.5281/zenodo.6407092,2020,Oege Dijk,"https://github.com/oegedijk/explainerdashboard

http://titanicexplainer.herokuapp.com/"
242,PLOT4ai,Privacy Library Of Threats 4 Artificial Intelligence (PLOT4ai),,"Businness and problem understanding; Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Beneficence; Autonomy; Non-Maleficence; Justice; Explicability; Non-Maleficence,Social Good; Well-being; Responsibility; Trust; Privacy; Security; Safety; Quality Data; Reliability; Prevention; Fairness; Trade-offs; Explicability; Interpretability,Does not apply,"4,4",Academic,Website; Resource Compendium; Tool Compendium,Does not apply,https://plot4.ai/,2022,Isabel Barberá,"https://plot4.ai/how-does-it-work

https://plot4.ai/assessments/quick-check

https://plot4.ai/library"
243,Lucid,,,"Collection, understanding and preparation of data; Performance evaluation",Explicability; Explicability,Interpretability,Computer Vision,"4,2",Academic,Code; Examples; Resource Compendium,Python,https://github.com/tensorflow/lucid,2018,TensorFlow Community,
244,APPFL,APPFL: Open-Source Software Framework for Privacy-Preserving Federated Learning,,Model setup and training,Non-Maleficence,Security; Privacy; Safety; Reliability,Computer Vision,"4,1",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.2202.03672,2022,"Minseok Ryu, Youngdae Kim, Kibaek Kim, Ravi K. Madduri","https://github.com/APPFL/APPFL

https://appfl.readthedocs.io/en/stable/"
245,NLP Test,NLP Test: Deliver Safe & Effective Language Models,,"Collection, understanding and preparation of data; Performance evaluation",Non-Maleficence; Justice,Safety; Reliability; Fairness; Auditability,Natural Language Processing,"4,4",Private,Code; Website,Python,https://github.com/JohnSnowLabs/nlptest,2022,John Snow Labs,https://nlptest.org/
246,multi-imbalance,multi-imbalance: Open Source Python Toolbox for Multi-class Imbalanced Classification,,"Collection, understanding and preparation of data; Performance evaluation",Justice; Non-Maleficence,Fairness; Quality Data; Reliability,Multi-class Classification,"4,2",Academic,Code; Article,Python,https://doi.org/10.1007/978-3-030-67670-4_36,2021,"Jacek Grycza, Damian Horna, Hanna Klimczak, Mateusz Lango, Kamil Pluciński, Jerzy Stefanowski ","https://github.com/damian-horna/multi-imbalance

http://www.cs.put.poznan.pl/mlango/publications/multiimbalance/

https://sci-hub.ru/10.1007/978-3-030-67670-4_36"
247,Ensemble Classifiers for Imbalanced Dataset,,,Model setup and training,Justice,Fairness,Binary Classification,"3,8",Academic,Code,Python,https://github.com/hmohebbi/ensembleforImbalance,2020,Hosein Mohebbi,https://github.com/bharlow058/SMOTE-Variants
248,Equalization Ensemble method (EASE),Equalization ensemble for large scale highly imbalanced data classification,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Justice; Non-Maleficence; Non-Maleficence,Fairness; Quality Data; Reliability,Binary Classification,4,Academic,Code; Article,Python,https://doi.org/10.1016/j.knosys.2022.108295,2022,"Jinjun Ren, Yuping Wang, Mingqian Mao, Yiu-ming Cheung",https://github.com/JinJunRen/EASE
249,Self-paced Ensemble (SPE),Self-paced Ensemble for Highly Imbalanced Massive Data Classification,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Justice; Non-Maleficence; Non-Maleficence,Fairness; Quality Data; Reliability,Multi-class Classification; Computer Vision,"4,3",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.1909.03500,2019,"Zhining Liu, Wei Cao, Zhifeng Gao, Jiang Bian, Hechang Chen, Yi Chang, Tie-Yan Liu",https://github.com/ZhiningLiu1998/self-paced-ensemble
250,Singular Vector Canonical Correlation Analysis (SVCCA),SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability,,Performance evaluation,Explicability,Interpretability,Computer Vision; Dimensionality Reduction,4,Academic; Private,Code; Article,Python,https://doi.org/10.48550/arXiv.1706.05806,2017,"Maithra Raghu, Justin Gilmer, Jason Yosinski, Jascha Sohl-Dickstein",https://github.com/google/svcca
251,Network Dissection,Network Dissection: Quantifying Interpretability of Deep Visual Representations,,Performance evaluation,Explicability,Interpretability,Computer Vision,"4,2",Academic,Article; Code; Website,Python,https://doi.org/10.1109/CVPR.2017.354,2017,"Bolei Zhou, David Bau, Aude Oliva, Antonio Torralba","https://github.com/CSAILVision/NetDissect

http://netdissect.csail.mit.edu/

http://netdissect.csail.mit.edu/final-network-dissection.pdf"
252,GANDissect,GAN Dissection: Visualizing and Understanding Generative Adversarial Networks,,Performance evaluation,Explicability,Interpretability,Computer Vision,"4,2",Academic,Article; Code; Website,Python,https://doi.org/10.48550/arXiv.1811.10597,2018,"David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B. Tenenbaum, William T. Freeman, Antonio Torralba","https://github.com/CSAILVision/GANDissect

https://gandissect.csail.mit.edu/"
253,Dissect,Understanding the Role of Individual Units in a Deep Network,,Performance evaluation,Explicability,Interpretability,Computer Vision,"4,2",Academic,Article; Code; Website,Python,https://doi.org/10.1073/pnas.1907375117,2020,"David Bau, Jun-Yan Zhu, Hendrik Strobelt, Agata Lapedriza, Bolei Zhou, Antonio Torralba","https://github.com/davidbau/dissect

https://dissect.csail.mit.edu/"
254,Summit,Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations,,Performance evaluation,Explicability,Interpretability,Computer Vision,"4,5",Academic,Code; Article; Program,JavaScript; Python,https://doi.org/10.1109/TVCG.2019.2934659,2020,"Fred Hohman, Haekyu Park, Caleb Robinson, Duen Horng Polo Chau","https://github.com/fredhohman/summit/

https://fredhohman.com/summit/

https://fredhohman.com/papers/19-summit-vast.pdf"
255,Testing with Concept Activation Vectors (TCAV),Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),,Model setup and training; Performance evaluation,Explicability; Explicability,Interpretability,Computer Vision; Binary Classification,"4,3",Private; Academic,Code,Python,https://doi.org/10.48550/arXiv.1711.11279,2017,"Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, Rory Sayres",https://github.com/tensorflow/tcav
256,How to Prevent Discriminatory Outcomes in Machine Learning,,,Businness and problem understanding; Businness and problem understanding; Planning and design,Justice; Beneficence; Autonomy,Inclusion; Fairness; Social Good; Well-being; Human Rights; Agency,Does not apply,"4,2",NGO,White Paper; Guide; Theoretical Framework,Does not apply,https://www.weforum.org/whitepapers/how-to-prevent-discriminatory-outcomes-in-machine-learning,2018,World Economic Forum (WEF),
257,Strategy Atlas,StrategyAtlas: Strategy Analysis for Machine Learning Interpretability,,"Collection, understanding and preparation of data; Performance evaluation",Non-Maleficence; Explicability,Explicability; Interpretability; Quality Data,Binary Classification; Multi-class Classification; Clustering,"4,6",Private; Academic,Article; Website,Python,https://doi.org/10.1109/TVCG.2022.3146806,2022,"Dennis Collaris, Jarke J. van Wijk","https://explaining.ml/

https://explaining.ml/strategyatlas/demo/

https://explaining.ml/explainexplore"
258,SecretFlow,,,"Collection, understanding and preparation of data; Model setup and training",Non-Maleficence; Non-Maleficence,Security; Privacy; Safety; Reliability,Computer Vision; Binary Classification; Multi-class Classification; Regression,"4,6",Public; Academic,Code,Python,https://github.com/secretflow/secretflow,2022,SecretFlow Open Source Community,"https://www.secretflow.org.cn/docs/secretflow/latest/en-US

https://www.secretflow.org.cn/"
259,Recommendation on the Ethics of Artificial Intelligence,,,Businness and problem understanding; Planning and design,Beneficence; Non-Maleficence,Responsibility; Sustainability; Well-being; Human Rights; Social Good; Reliability; Prevention,Does not apply,4,NGO,Guide; Theoretical Framework; Principles,Does not apply,https://unesdoc.unesco.org/ark:/48223/pf0000381137,2021,UNESCO,https://www.unesco.org/en/articles/recommendation-ethics-artificial-intelligence
260,Responsible Machine Learning with Python,,,Model setup and training; Performance evaluation,Explicability; Justice,Explicability; Interpretability; Fairness; Auditability,Binary Classification,4,Academic,Code; Resource Compendium; Examples,Python; Java,https://github.com/jphall663/interpretable_machine_learning_with_python,2018,"J.P Hall, Contributors",
261,Fastshap,,,Performance evaluation,Explicability,Explicability; Interpretability,Regression; Binary Classification; Multi-class Classification,4,Academic,Code,R,https://github.com/bgreenwell/fastshap,2019,Brandon Greenwell,https://bgreenwell.github.io/fastshap/
262,From Principles to Practice An interdisciplinary framework to operationalise AI ethics,,,Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice,Social Good; Well-being; Responsibility; Trust; Sustainability; Safety; Privacy; Accountability; Transparency; Reliability; Agency; Fairness; Auditability,Does not apply,"4,5",Academic; Private,Practical Framework; Guide,Does not apply,https://doi.org/10.11586/2020013,2020,"Sebastian Hallensleben, Carla Hustedt, Lajla Fetic, Torsten Fleischer, Paul Grünke, Thilo Hagendorff, Andreas Hauschke, Marc Hauer, Jessica Heesen, Michael Herrmann, Rafaela Hillerbrand, Emeritus Christoph Hubig, Andreas Kaminski, Tobias Krafft, Wulf Loh, Philipp Otto, Michael Puntschuh",
263,Responsible AI Toolbox (rAI-toolbox),Tools and Practices for Responsible AI Engineering,,Model setup and training; Performance evaluation; Deployment and monitoring,Non-Maleficence; Explicability; Explicability,Reproducibility; Reliability; Security; Explicability; Interpretability,Computer Vision,"4,2",Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.2201.05647,2022,"Ryan Soklaski, Justin Goodwin, Olivia Brown, Michael Yee, Jason Matterer","https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox

https://mit-ll-responsible-ai.github.io/responsible-ai-toolbox/"
264,AI Ethics: From principles to practice - Towards trustworthy AI design and audit,,,Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Justice,Social Good; Responsibility; Accountability; Transparency; Prevention; Reliability; Fairness; Auditability; Trade-offs,Does not apply,"4,3",Private,Website; Tool Compendium; Practical Framework; Guide; Case Studies,Does not apply,https://www.fujitsu.com/global/about/research/technology/aiethics/,2022,Fujitsu Research,https://www.fujitsu.com/global/about/research/technology/ai/aiethics/index.html
265,Trustworthy Artificial Intelligence: A Review,Trustworthy Artificial Intelligence: A Review,,Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Responsibility; Trust; Accountability; Reliability; Privacy; Agency; Fairness; Transparency; Interpretability,Does not apply,"4,2",Academic,Article; Resource Compendium; Tool Compendium,Does not apply,https://doi.org/10.1145/3491209,2022,"Davinder Kaur, Suleyman Uslu, Kaley J. Rittichier, Arjan Durresi",https://cs.iupui.edu/~adurresi/papers/kaur2022trustworthy.pdf
266,Explainable Deep Learning: A Field Guide for the Uninitiated,Explainable Deep Learning: A Field Guide for the Uninitiated,,Planning and design,Explicability,Explicability; Interpretability,Does not apply,"4,1",Academic,Article; Guide; Resource Compendium,Does not apply,https://doi.org/10.1613/jair.1.13200,2022,"Gabrielle Ras, Ning Xie, Marcel van Gerven, Derek Doran","https://dl.acm.org/doi/10.1613/jair.1.13200

https://github.com/utkuozbulak/pytorch-cnn-visualizations"
267,A Survey on Trust Evaluation Based on Machine Learning,A Survey on Trust Evaluation Based on Machine Learning,,Businness and problem understanding; Planning and design,Non-Maleficence; Justice,Security; Privacy; Quality Data; Reliability; Auditability,Does not apply,4,Academic,Article; Resource Compendium,Does not apply,https://doi.org/10.1145/3408292,2020,"Jingwen Wang, Xuyang Jing, Zheng Yan, Yulong Fu, Witold Pedrycz, Laurence T. Yang",
268,Fair preprocessing: towards understanding compositional fairness of data transformers in machine learning pipeline,Fair preprocessing: towards understanding compositional fairness of data transformers in machine learning pipeline,,"Collection, understanding and preparation of data",Justice,Fairness,Binary Classification,"4,1",Academic,Article; Code; Dataset,Python,https://doi.org/10.1145/3468264.3468536,2021,"Sumon Biswas, Hridesh Rajan",https://github.com/sumonbis/FairPreprocessing
269,MAAT,MAAT: a novel ensemble approach to addressing fairness and performance bugs for machine learning software,,Model setup and training,Justice,Fairness,Binary Classification; Regression; Computer Vision,"4,2",Academic,Article; Code,Python,https://doi.org/10.1145/3540250.3549093,2022,"Zhenpeng Chen, Jie M. Zhang, Federica Sarro, Mark Harman","https://discovery.ucl.ac.uk/id/eprint/10152903/1/FSE22_Fairness.pdf

https://github.com/chenzhenpeng18/FSE22-MAAT"
270,PRDNN,Provable repair of deep neural networks,,Model setup and training; Performance evaluation,Non-Maleficence; Justice,Security; Safety; Reliability; Trade-offs,Computer Vision,"4,1",Academic,Article; Code,Python,https://doi.org/10.1145/3453483.3454064,2021,"Matthew Sotoudeh, Aditya V. Thakur",https://github.com/95616ARG/PRDNN
271,FINS,FINS Auditing Framework: Group Fairness for Subset Selections,,"Collection, understanding and preparation of data",Justice,Fairness,Binary Classification; Multi-class Classification,4,Academic,Article; Code,Python,https://doi.org/10.1145/3514094.3534160,2022,"Kathleen Cachel, Elke Rundensteiner ","https://github.com/kcachel/fins

https://web.archive.org/web/20220802185007id_/https://dl.acm.org/doi/pdf/10.1145/3514094.3534160"
272,How Cognitive Biases Affect XAI-assisted Decision-making: A Systematic Review,How Cognitive Biases Affect XAI-assisted Decision-making: A Systematic Review,,Businness and problem understanding; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Does not apply,Does not apply,Academic,Article; Resource Compendium,Does not apply,https://doi.org/10.1145/3514094.3534164,2022,"Astrid Bertrand, Rafik Belloum, James R. Eagan, Winston Maxwell","https://hal.telecom-paris.fr/hal-03684457v1/document#:~:text=cognitive%20biases%2C%20revealing%20four%20main,on%20the%20contrary%2C%204)%20some"
273,On decomposing a deep neural network into modules,On decomposing a deep neural network into modules,,Model setup and training; Performance evaluation,Beneficence; Beneficence,Sustainability,Multi-class Classification,"3,8",Academic,Article; Code,Python,https://doi.org/10.1145/3368089.3409668,2020,"Rangeet Pan, Hridesh Rajan",https://github.com/rangeetpan/decomposeDNNintoModules
274,Libra,Perfectly parallel fairness certification of neural networks,,Model setup and training; Performance evaluation,Justice; Justice,Fairness; Auditability,Binary Classification,"4,2",Academic,Article; Code,Python,https://doi.org/10.1145/3428253,2020,"Caterina Urban, Maria Christakis, Valentin Wüstholz, Fuyuan Zhang","https://github.com/caterinaurban/Libra

https://caterinaurban.github.io/publication/fairness/

https://caterinaurban.github.io/project/libra/

https://caterinaurban.github.io/talk/lorentz2021b/"
275,DEBAR,Detecting numerical bugs in neural network architectures,,Performance evaluation; Deployment and monitoring,Non-Maleficence; Justice,Security; Safety; Reliability; Auditability,Binary Classification; Multi-class Classification,"4,3",Academic,Article; Code,Python,https://doi.org/10.1145/3368089.3409720,2020,"Yuhao Zhang, Luyao Ren, Liqian Chen, Yingfei Xiong, Shing-Chi Cheung, Tao Xie","https://github.com/ForeverZyh/DEBAR

https://sci-hub.se/10.1145/3368089.3409720"
276,Test Selection for Deep Learning Systems,Test Selection for Deep Learning Systems,,"Collection, understanding and preparation of data",Non-Maleficence,Quality Data; Reliability,Multi-class Classification; Computer Vision,"3,9",Academic,Article; Code,Python,https://doi.org/10.1145/3417330,2021,"Wei Ma, Mike Papadakis, Anestis Tsakmalis, Maxime Cordy, Yves Le Traon",https://github.com/TestSelection/TestSelection
277,GraphicalAI,GraphicalAI: A User-Centric Approach to Develop Artificial Intelligence and Machine Learning Applications using a Visual and Graphical Language,,Planning and design; Model setup and training,Autonomy; Explicability,Agency; Literacy; Interpretability,Regression; Binary Classification; Multi-class Classification,"4,2",Academic,Program; Code; Article,Python,https://doi.org/10.1145/3456146.3456155,2021,"Andrew Shen, Yu Sun","https://github.com/AndrewHC36/GraphicalAI

https://sci-hub.ru/10.1145/3456146.3456155"
278,Towards training reproducible deep learning models,Towards training reproducible deep learning models,,Model setup and training; Performance evaluation; Deployment and monitoring,Non-Maleficence; Non-Maleficence; Non-Maleficence,Reproducibility; Transparency; Accountability,Regression; Multi-class Classification; Natural Language Processing; Computer Vision,4,Academic,Article; Guidelines; Examples,Python,https://doi.org/10.1145/3510003.3510163,2022,"Boyuan Chen, Mingzhi Wen, Yong Shi, Dayi Lin, Gopi Krishnan Rajbahadur, Zhen Ming (Jack) Jiang","https://github.com/nemo9cby/ICSE2022Rep

https://github.com/nemo9cby/repro_exp

https://github.com/keras-team/keras/issues/14671

https://arxiv.org/abs/2202.02326"
279,Building Trustworthy AI Solutions: A Case for Practical Solutions for Small Businesses,Building Trustworthy AI Solutions: A Case for Practical Solutions for Small Businesses,,Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Trust; Responsibility; Reliability; Agency; Fairness; Transparency,Does not apply,"4,2",Academic,Article; Tool Compendium; Guide,Does not apply,https://doi.org/10.1109/TAI.2021.3137091,2021,"Keeley Alexandra Crockett, Luciano Gerber, Annabel Latham, Edwin Colyer",
280,Ensembled Membership Auditing (EMA),A Dataset Auditing Method for Collaboratively Trained Machine Learning Models,,Model setup and training; Performance evaluation,Non-Maleficence; Justice,Accountability; Privacy; Auditability,Computer Vision,4,Academic,Article; Code,Python,https://doi.org/10.1109/TMI.2022.3220706,2022,"Yangsibo Huang, Chun-Yin Huang, Xiaoxiao Li, Kai Li",https://github.com/Hazelsuko07/EMA
281,Ethical Framework Associated with AI,Ethical Framework Associated with AI,,Businness and problem understanding; Businness and problem understanding,Beneficence; Non-Maleficence,Responsibility; Social Good; Trust; Accountability; Transparency; Privacy,Does not apply,Does not apply,Academic,Article; Guide,Does not apply,https://doi.org/10.1002/9781119831808.ch3,2021,Jérôme Béranger Leroy,https://sci-hub.ru/10.1002/9781119831808.ch3
282,BENN,BENN: Bias Estimation Using a Deep Neural Network,,Performance evaluation,Justice,Fairness; Auditability,Binary Classification,"3,5",Academic,Article; Code,Python,https://doi.org/10.1109/TNNLS.2022.3172365,2022,"Amit Giloni, Edita Grolman, Tanja Hagemann, Ronald Fromm, Sebastian Fischer, Yuval Elovici, Asaf Shabtai",https://arxiv.org/abs/2012.12537
283,An instrument to evaluate the maturity of bias governance capability in artificial intelligence projects,An instrument to evaluate the maturity of bias governance capability in artificial intelligence projects,,"Planning and design; Collection, understanding and preparation of data; Model setup and training; Deployment and monitoring",Justice; Justice; Justice; Justice; Governance,Fairness; Auditability,Does not apply,"4,2",Private; Academic,Article; Practical Framework; Case Studies,Does not apply,https://doi.org/10.1147/JRD.2019.2915062,2019,"Daphne L. Coates, Andrew Martin","https://wbs.qualtrics.com/jfe/form/SV_0oewgtUNwnhE1WB

https://wbs.qualtrics.com/jfe/form/SV_83d1I3Z3yifmIAZ

https://sci-hub.ru/10.1147/JRD.2019.2915062

https://cdt.org/insights/digital-decisions-tool/"
284,Ethics and Good Practice in Computational Paralinguistics,Ethics and Good Practice in Computational Paralinguistics,,Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Responsibility; Inclusion; Privacy; Quality Data; Agency; Auditability; Interpretability,Does not apply,Does not apply,Academic,Article; Guide,Does not apply,https://doi.org/10.1109/TAFFC.2020.3021015,2020,"Anton Batliner, Simone Hantke, Björn W. Schuller",https://d-nb.info/1218972033/34
285,Exosoul,A Software Exoskeleton to Protect and Support Citizen’s Ethics and Privacy in the Digital World,,Businness and problem understanding,Non-Maleficence,Privacy; Safety,Does not apply,"3,6",Academic,Article; Program,Does not apply,https://doi.org/10.1109/ACCESS.2019.2916203,2019,"Marco Autili, Davide Di Ruscio, Paola Inverardi, Patrizio Pelliccione, Massimo Tivoli","https://exosoul.disim.univaq.it/

https://youtu.be/GcrxJYmGmCU

https://arxiv.org/pdf/2204.01588.pdf"
286,RAInS Ontology,"Using Knowledge Graphs to Unlock Practical Collection, Integration, and Audit of AI Accountability Information",,Model setup and training; Deployment and monitoring,Non-Maleficence; Non-Maleficence,Accountability,Does not apply,"3,8",Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1109/ACCESS.2022.3188967,2022,"Iman Naja, Milan Markovic, Peter Edwards, Wei Pang, Caitlin Cottrill, Rebecca Williams","https://rains-uoa.github.io/RAInS-Ontology/v2.0/index-en.html

https://rains-uoa.github.io/SAO-Ontology/index-en.html

https://github.com/RAINS-UOA/RAInS-Ontology"
287,Z-Inspection,Z-Inspection®: A Process to Assess Trustworthy AI,,Businness and problem understanding; Deployment and monitoring,Non-Maleficence; Justice,Accountability; Auditability,Does not apply,"4,2",Academic,Article; Practical Framework; Guide,Does not apply,https://doi.org/10.1109/TTS.2021.3066209,2021,"Roberto V. Zicari, John Brodersen, James Brusseau, Boris Düdder, Timo Eichhorn, Todor Ivanov, Georgios Kararigas, Pedro Kringen, Melissa McCullough, Florian Möslein, Naveed Mushtaq, Gemma Roig, Norman Stürtz, Karsten Tolle, Jesmin Jahan Tithi, Irmhild van Halem, Magnus Westerlund","https://z-inspection.org/

https://github.com/dennisrv/z-inspection-toolkit

https://github.com/dennisrv/z-inspection-issue-visualizer"
288,AI Ethics in Smart Healthcare,AI Ethics in Smart Healthcare,,Businness and problem understanding; Businness and problem understanding; Businness and problem understanding,Non-Maleficence; Autonomy; Justice,Transparency; Safety; Privacy; Agency; Fairness,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1109/MCE.2022.3220001,2022,Sudeep Pasricha,https://arxiv.org/abs/2211.06346
289,Design of a Human Factors Questionnaire to Evaluate Digital Solutions Developed for Industrial Work,Design of a Human Factors Questionnaire to Evaluate Digital Solutions Developed for Industrial Work,,Deployment and monitoring,Beneficence,Social Good,Does not apply,"3,9",Academic,Article; Practical Framework,Does not apply,https://doi.org/10.54941/ahfe1001992,2022,"Susanna Aromaa, Päivi Heikkilä",
290,TAII Framework for Trustworthy AI Systems,TAII Framework for Trustworthy AI Systems,,Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Justice,Social Good; Sustainability; Responsibility; Trust; Prevention; Auditability,Does not apply,4,Academic,Article; Guide; Theoretical Framework,Does not apply,https://doi.org/10.1007/978-3-031-18275-4_7,2022,Josef Baker-Brunnbauer,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3914105
291,FRIA Framework,Practical fundamental rights impact assessments,,Businness and problem understanding; Businness and problem understanding; Planning and design,Beneficence; Non-Maleficence; Justice,Human Rights; Social Good; Well-being; Accountability; Reliability; Prevention; Auditability; Trade-offs,Does not apply,"4,3",Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1093/ijlit/eaac018,2022,"Heleen Janssen, Michelle Seng Ah Lee, Jatinder Singh",
292,AI Incidents Annotation Using Stakeholder Model Based On ISO 26000 Guidelines,AI Incidents Annotation Using Stakeholder Model Based On ISO 26000 Guidelines,,Deployment and monitoring; Deployment and monitoring; Deployment and monitoring,Justice; Autonomy; Beneficence,Prevention; Human Oversight; Responsibility,Does not apply,"3,9",Academic,Theory Document; Code; Website,Does not apply,https://www.scss.tcd.ie/publications/theses/diss/2022/TCD-SCSS-DISSERTATION-2022-089.pdf,2022,Omkar Pramod Padir,"https://github.com/OmkarPadir/Dissertation

https://www.aiaaic.org/

https://www.iso.org/obp/ui#iso:std:iso:26000:ed-1:v1:en"
293,"Ethical Tools, Methods and Principles in Software Engineering and Development: Case Ethical User Stories","Ethical Tools, Methods and Principles in Software Engineering and Development: Case Ethical User Stories",,Planning and design; Planning and design,Beneficence; Non-Maleficence,Social Good; Trust; Reliability,Does not apply,4,Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1007/978-3-031-21388-5_48,2022,Erika Halme,"https://link.springer.com/chapter/10.1007/978-3-030-78098-2_3

http://library.lol/main/BDAFD407E4D71467FD79FD9FDC024B0A"
294,Ethical FRAPPE – an adapted draft framework for ethical AIED,Ethical FRAPPE – an adapted draft framework for ethical AIED,,Businness and problem understanding; Planning and design,Beneficence; Justice,Social Good; Responsibility; Human Rights; Fairness,Does not apply,4,Academic,Article; Theoretical Framework,Does not apply,https://ceur-ws.org/Vol-3292/DCECTEL2022_paper06.pdf,2022,"Bhoomika Agarwal, Corrie Urlings, Giel van Lankveld, Roland Klemke",https://research.ou.nl/en/publications/ethical-frappe-an-adapted-draft-framework-for-ethical-aied
295,A Trust Framework for Government Use of Artificial Intelligence and Automated Decision Making,A Trust Framework for Government Use of Artificial Intelligence and Automated Decision Making,,Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability; Governance,Responsibility; Trust; Human Rights; Accountability; Transparency; Reliability; Agency; Prevention; Auditability; Interpretability; Traceability,Does not apply,"4,2",Academic,Article; Practical Framework; Resource Compendium,Does not apply,https://doi.org/10.48550/arXiv.2208.10087,2022,"Pia Andrews, Tim de Sousa, Bruce Haefele, Matt Beard, Marcus Wigan, Abhinav Palia, Kathy Reid, Saket Narayan, Morgan Dumitru, Alex Morrison, Geoff Mason, Aurelie Jacquet",https://www.themandarin.com.au/211859-building-trustworthy-ai-in-the-special-context-of-public-service/
296,Virtual Assistants: A Code of Ethics,Virtual Assistants: A Code of Ethics,,Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy,Diversity; Inclusion; Security; Privacy; Transparency,Does not apply,Does not apply,Academic,Code of Ethics; Article,Does not apply,https://doi.org/10.26686/wfeess.vi.7652,2022,Tian Welgemoed,
297,Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics,Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics,,Businness and problem understanding; Planning and design,Non-Maleficence; Beneficence,Social Good; Responsibility; Reliability,Does not apply,4,Academic,Article; Tool Compendium,Does not apply,https://doi.org/10.48550/arXiv.2202.08792,2022,"Richmond Y. Wong, Michael A. Madaio, Nick Merrill",
298,Lens,Democratizing Ethical Assessment of Natural Language Generation Models,,Performance evaluation; Deployment and monitoring,Justice; Justice,Fairness; Auditability,Natural Language Processing,4,Academic,Code; Article,Python,https://doi.org/10.48550/arXiv.2207.10576,2022,"Amin Rasekh, Ian Eisenberg",https://github.com/credo-ai/credoai_lens
299,An Ethical Framework for Guiding the Development of Affectively-Aware Artificial Intelligence,An Ethical Framework for Guiding the Development of Affectively-Aware Artificial Intelligence,,Businness and problem understanding; Planning and design; Planning and design,Justice; Non-Maleficence; Beneficence,Responsibility; Social Good; Privacy; Transparency; Accountability; Prevention; Fairness,Does not apply,Does not apply,Academic,Article; Theoretical Framework,Does not apply,https://doi.org/10.48550/arXiv.2107.13734,2021,Desmond C. Ong,
300,"Computability, Complexity, Consistency and Controllability: A Four C's Framework for cross-disciplinary Ethical Algorithm Research","Computability, Complexity, Consistency and Controllability: A Four C's Framework for cross-disciplinary Ethical Algorithm Research",,Businness and problem understanding; Planning and design,Non-Maleficence; Autonomy,Reliability; Agency,Does not apply,Does not apply,Academic,Article; Theoretical Framework,Does not apply,https://doi.org/10.48550/arXiv.2102.04234,2021,Elija Perrier,
301,The Moral-IT Deck,The Moral-IT Deck: A Tool for Ethics by Design,,Planning and design; Planning and design; Planning and design; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Social Good; Well-being; Trust; Responsibility; Sustainability; Security; Safety; Privacy; Accountability; Transparency; Agency; Fairness; Prevention; Interpretability,Does not apply,"4,2",Academic,Article; Practical Framework,Does not apply,https://doi.org/10.48550/arXiv.2007.07514,2020,"Lachlan Urquhart, Peter Craigon",https://lachlansresearch.com/the-moral-it-legal-it-decks/
302,Audit and Assurance of AI Algorithms: A framework to ensure ethical algorithmic practices in Artificial Intelligence,Audit and Assurance of AI Algorithms: A framework to ensure ethical algorithmic practices in Artificial Intelligence,,Planning and design; Planning and design,Non-Maleficence; Justice,Accountability; Auditability,Does not apply,Does not apply,Academic,Article; Theoretical Framework,Does not apply,https://doi.org/10.48550/arXiv.2107.14046,2021,"Ramya Akula, Ivan Garibay",
303,AI Governance and Ethics Framework for Sustainable AI and Sustainability,AI Governance and Ethics Framework for Sustainable AI and Sustainability,,Businness and problem understanding; Planning and design,Beneficence; Beneficence; Governance,Responsibility; Sustainability; Social Good; Inclusion; Diversity,Does not apply,Does not apply,Academic,Article; Theoretical Framework,Does not apply,https://doi.org/10.48550/arXiv.2210.08984,2022,Mahendra Samarawickrama,
304,A Toolkit to Enable the Design of Trustworthy AI,A Toolkit to Enable the Design of Trustworthy AI,,Planning and design; Planning and design; Planning and design; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Inclusion; Social Good; Privacy; Agency; Fairness; Explicability,Does not apply,4,Academic,Article; Tool Compendium,Does not apply,https://doi.org/10.1007/978-3-030-90963-5_41,2021,"Stefan Schmager, Sonia Sousa",https://www.researchgate.net/publication/356088679_A_Toolkit_to_Enable_the_Design_of_Trustworthy_AI
305,Ethical Foresight Analysis: What It Is and Why It Is Needed?,Ethical Foresight Analysis: What It Is and Why It Is Needed?,,Businness and problem understanding,Non-Maleficence,Safety; Prevention,Does not apply,Does not apply,Academic,Article; Resource Compendium,Does not apply,https://doi.org/10.1007/s11023-020-09521-y,2021,"Luciano Floridi, Andrew Strait",
306,AI4People,"AI4People - An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations",,Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Businness and problem understanding,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Social Good; Accountability; Agency; Fairness; Interpretability,Does not apply,"4,2",Academic,Article; Theoretical Framework,Does not apply,https://doi.org/10.1007/s11023-018-9482-5,2018,"Luciano Floridi, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo Pagallo, Francesca Rossi, Burkhard Schafer, Peggy Valcke, Effy Vayena","https://www.eismd.eu/ai4people/

https://futurescope.digicatapult.org.uk/wp-content/uploads/2023/04/DC_AI_Ethics_Framework-2021.pdf"
307,CADEX - Constrained Adversarial Explanations,Explaining Deep Learning Models with Constrained Adversarial Examples,,Performance evaluation,Explicability,Explicability,Binary Classification,"3,9",Academic,Code; Article,Python,https://doi.org/10.1007/978-3-030-29908-8_4,2019,"Jonathan Moore, Nils Hammerla, Chris Watkins","https://github.com/spore1/cadex

https://arxiv.org/abs/1906.10671"
308,AequeVox,AequeVox: Automated Fairness Testing of Speech Recognition Systems,,Performance evaluation,Justice,Fairness,Natural Language Processing,"4,2",Academic,Code; Article,Python,https://doi.org/10.1007/978-3-030-99429-7_14,2022,"Sai Sathiesh Rajan, Sakshi Udeshi, Sudipta Chattopadhyay",https://github.com/sparkssss/AequeVox
309,Supporting Human Autonomy in AI Systems: A Framework for Ethical Enquiry,Supporting Human Autonomy in AI Systems: A Framework for Ethical Enquiry,,Businness and problem understanding,Autonomy,Agency,Does not apply,4,Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1007/978-3-030-50585-1_2,2020,"Rafael A. Calvo, Dorian Peters, Karina Vold & Richard M. Ryan",
310,DOS (Deep Over-Sampling) Framework,Deep Over-sampling Framework for Classifying Imbalanced Data,,Model setup and training,Justice,Fairness,Computer Vision,"3,9",Academic,Code; Article,Python,https://doi.org/10.1007/978-3-319-71249-9_46,2017,Shin Ando & Chun Yuan Huang,"https://github.com/m-zayan/DOS-Framework-PyTorch

https://github.com/Salehbigdeli/DOS-Classifying-Imbalanced"
311,Privacy-Preserving Technologies for Trusted Data Spaces,Privacy-Preserving Technologies for Trusted Data Spaces,,Model setup and training,Non-Maleficence,Security; Privacy,Regression; Multi-class Classification; Clustering,"4,1",Academic; Public,Article; Code; Website,Python,https://doi.org/10.1007/978-3-030-78307-5_6,2021,"Susanna Bonura, Davide Dalle Carbonare, Roberto Díaz-Morales, Marcos Fernández-Díaz, Lucrezia Morabito, Luis Muñoz-González, Chiara Napione, Ángel Navia-Vázquez, Mark Purcell","https://musketeer.eu/project/

https://github.com/Musketeer-H2020

https://github.com/IBM/Musketeer-Client

https://link.springer.com/chapter/10.1007/978-3-030-98636-0_5"
312,VerifAI,VERIFAI: A Toolkit for the Formal Design and Analysis of Artificial Intelligence-Based Systems,,Performance evaluation; Deployment and monitoring,Non-Maleficence; Justice,Security; Reliability; Prevention; Auditability,Computer Vision,4,Academic,Code; Article,Python,https://doi.org/10.1007/978-3-030-25540-4_25,2019,"Tommaso Dreossi, Daniel J. Fremont, Shromona Ghosh, Edward Kim, Hadi Ravanbakhsh, Marcell Vazquez-Chanlatte, Sanjit A. Seshia",https://github.com/BerkeleyLearnVerify/VerifAI
313,DLV (Deep Learning Verification),Safety Verification of Deep Neural Networks,,Model setup and training,Non-Maleficence,Safety; Security; Reliability,Computer Vision,4,Academic,Code; Article,Python,https://doi.org/10.1007/978-3-319-63387-9_1,2017,"Xiaowei Huang, Marta Kwiatkowska, Sen Wang, Min Wu",https://github.com/verideep/dlv
314,X-SPELLS,Explaining Sentiment Classification with Synthetic Exemplars and Counter-Exemplars,,Performance evaluation,Explicability,Explicability; Interpretability,Multi-class Classification,4,Academic,Code; Article,Python,https://doi.org/10.1007/978-3-030-61527-7_24,2020,"Orestis Lampridis, Riccardo Guidotti, Salvatore Ruggieri",https://github.com/lstate/X-SPELLS-V2
315,Continuous Auditing of Artificial Intelligence: a Conceptualization and Assessment of Tools and Frameworks,Continuous Auditing of Artificial Intelligence: a Conceptualization and Assessment of Tools and Frameworks,,Businness and problem understanding; Planning and design,Beneficence; Justice,Responsibility; Auditability,Does not apply,"4,1",Academic,Article; Tool Compendium; Resource Compendium,Does not apply,https://doi.org/10.1007/s44206-022-00022-2,2022,"Matti Minkkinen, Joakim Laine, Matti Mäntymäki",
316,AI bias: exploring discriminatory algorithmic decision-making models and the application of possible machine-centric solutions adapted from the pharmaceutical industry,AI bias: exploring discriminatory algorithmic decision-making models and the application of possible machine-centric solutions adapted from the pharmaceutical industry,,Performance evaluation; Deployment and monitoring,Justice; Justice,Fairness; Auditability,Does not apply,4,Academic,Practical Framework; Article,Python,https://doi.org/10.1007/s43681-022-00138-8,2022,Lorenzo Belenguer,
317,Ethical funding for trustworthy AI: proposals to address the responsibilities of funders to ensure that projects adhere to trustworthy AI practice,Ethical funding for trustworthy AI: proposals to address the responsibilities of funders to ensure that projects adhere to trustworthy AI practice,,Businness and problem understanding; Planning and design,Beneficence; Beneficence,Responsibility; Social Good; Trust,Does not apply,"4,1",Academic,Article; Case Studies; Practical Framework; Resource Compendium,Does not apply,https://doi.org/10.1007/s43681-021-00069-w,2022,"Allison Gardner, Adam Leon Smith, Adam Steventon, Ellen Coughlan, Marie Oldfield",
318,SleepXAI,SleepXAI: An explainable deep learning approach for multi-class sleep stage identification,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Multi-class Classification,"3,8",Academic,Code; Article,Python,https://doi.org/10.1007/s10489-022-04357-8,2022,"Micheal Dutt, Surender Redhu, Morten Goodwin, Christian W. Omlin",https://github.com/michealdutt/SleepXAI-An-Explainable-Deep-Learning-approach-for-Multi-class-Sleep-Stage-Identification
319,Machine Learning for Health: Algorithm Auditing & Quality Control,Machine Learning for Health: Algorithm Auditing & Quality Control,,"Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Beneficence; Non-Maleficence; Justice; Justice; Justice,Social Good; Human Rights; Accountability; Reliability; Fairness; Auditability,Multi-class Classification; Computer Vision,"4,3",Academic; NGO,Article; Code; Website; Resource Compendium,Python,https://doi.org/10.1007/s10916-021-01783-y,2021,"Luis Oala, Andrew G. Murchison, Pradeep Balachandran, Shruti Choudhary, Jana Fehr, Alixandro Werneck Leite, Peter G. Goldschmidt, Christian Johner, Elora D. M. Schörverth, Rose Nakasi, Martin Meyer, Federico Cabitza, Pat Baird, Carolin Prabhu, Eva Weicken, Xiaoxuan Liu, Markus Wenzel, Steffen Vogler, Darlington Akogo, Shada Alsalamah, Emre Kazim, Adriano Koshiyama, Sven Piechottka, Sheena Macpherson, Ian Shadforth, Regina Geierhofer, Christian Matek, Joachim Krois, Bruno Sanguinetti, Matthew Arentz, Pavol Bielik, Saul Calderon-Ramirez, Auss Abbood, Nicolas Langer, Stefan Haufe, Ferath Kherif, Sameer Pujari, Wojciech Samek, Thomas Wiegand","https://health.aiaudit.org/

https://github.com/aiaudit-org/health-aiaudit-public

https://github.com/FG-AI4H

https://fg-ai4h.github.io/"
320,Data Ethics Decision Aid (DEDA) Framework,Data Ethics Decision Aid (DEDA): a dialogical framework for ethical inquiry of AI and data projects in the Netherlands,,Planning and design; Planning and design; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice,Responsibility; Social Good; Accountability; Privacy; Transparency; Literacy; Fairness,Does not apply,"4,4",Academic; Public,Article; Practical Framework; Tool Compendium; Guide,Does not apply,https://doi.org/10.1007/s10676-020-09577-5,2021,"Aline Shakti Franzke, Iris Muis, Mirko Tobias Schäfer","https://deda.dataschool.nl/en/

https://deda.dataschool.nl/en/handbook/"
321,T-EBAnO,Trusting deep learning natural-language models via local and global explanations,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Natural Language Processing,4,Academic,Code; Article,Python,https://doi.org/10.1007/s10115-022-01690-9,2022,"Francesco Ventura, Salvatore Greco, Daniele Apiletti, Tania Cerquitelli","https://github.com/EBAnO-Ecosystem/Text-EBAnO-Express

https://ebano-ecosystem.github.io/"
322,Variability and reproducibility in deep learning for medical image segmentation,Variability and reproducibility in deep learning for medical image segmentation,,Model setup and training; Performance evaluation,Non-Maleficence; Non-Maleficence,Reproducibility; Transparency,Computer Vision,4,Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1038/s41598-020-69920-0,2020,"Félix Renard, Soulaimane Guedria, Noel De Palma, Nicolas Vuillerme",
323,"Image fairness in deep learning: problems, models, and challenges","Image fairness in deep learning: problems, models, and challenges",,Planning and design,Justice,Fairness,Multi-class Classification; Computer Vision,4,Academic,Article; Resource Compendium; Tool Compendium,Does not apply,https://doi.org/10.1007/s00521-022-07136-1,2022,"Huan Tian, Tianqing Zhu, Wei Liu, Wanlei Zhou",
324,Towards Transparency by Design for Artificial Intelligence,Towards Transparency by Design for Artificial Intelligence,,Businness and problem understanding; Planning and design,Non-Maleficence; Non-Maleficence,Accountability; Transparency,Does not apply,Does not apply,Academic,Article; Theoretical Framework; Principles,Does not apply,https://doi.org/10.1007/s11948-020-00276-4,2020,"Heike Felzmann, Eduard Fosch-Villaronga, Christoph Lutz, Aurelia Tamò-Larrieux",
325,FMEA-AI,FMEA-AI: AI fairness impact assessment using failure mode and effects analysis,,Businness and problem understanding,Justice,Fairness; Auditability,Does not apply,"3,9",Academic,Article; Practical Framework; Examples,Does not apply,https://doi.org/10.1007/s43681-022-00145-9,2022,"Jamy Li, Mark Chignell",https://www.academia.edu/74413338/FMEA_AI_AI_fairness_impact_assessment_using_failure_mode_and_effects_analysis
326,Data-driven Research framework for TAI (DaRe4TAI),Trustworthy artificial intelligence,,Businness and problem understanding; Businness and problem understanding; Businness and problem understanding; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Trust; Social Good; Accountability; Privacy; Agency; Fairness; Interpretability,Does not apply,4,Academic,Article; Theoretical Framework; Resource Compendium,Does not apply,https://doi.org/10.1007/s12525-020-00441-4,2021,"Scott Thiebes, Sebastian Lins, Ali Sunyaev",
327,An external stability audit framework to test the validity of personality prediction in AI hiring,An external stability audit framework to test the validity of personality prediction in AI hiring,,Performance evaluation; Performance evaluation,Justice; Non-Maleficence,Fairness; Auditability; Reliability,Binary Classification,"4,2",Academic,Code; Article,Python,https://doi.org/10.1007/s10618-022-00861-0,2022,"Alene K. Rhea, Kelsey Markey, Lauren D’Arinzo, Hilke Schellmann, Mona Sloane, Paul Squires, Falaah Arif Khan, Julia Stoyanovich","https://github.com/DataResponsibly/hiring-stability-audit

https://github.com/DataResponsibly"
328,SPEED,"SPEED: secure, PrivatE, and efficient deep learning",,Model setup and training,Non-Maleficence,Security; Privacy,Multi-class Classification; Computer Vision,"3,9",Academic,Code; Article,Python,https://doi.org/10.1007/s10994-021-05970-3,2021,"Arnaud Grivet Sébert, Rafaël Pinot, Martin Zuber, Cédric Gouy-Pailler, Renaud Sirdey",https://github.com/Arnaud-GS/SPEED
329,Data minimization for GDPR compliance in machine learning models (AI Privacy Toolkit),Data minimization for GDPR compliance in machine learning models,,"Collection, understanding and preparation of data; Model setup and training",Non-Maleficence; Non-Maleficence,Privacy; Quality Data,Binary Classification; Multi-class Classification,"4,2",Private; Academic,Code; Article,Python,https://doi.org/10.1007/s43681-021-00095-8,2022,"Abigail Goldsteen, Gilad Ezov, Ron Shmelkin, Micha Moffie, Ariel Farkash","https://github.com/IBM/ai-privacy-toolkit

https://arxiv.org/abs/2008.04113

https://github.com/IBM/ai-minimization-toolkit"
330,Artificial Intelligence Regulation (AIR) Framework for Governance,Artificial Intelligence Regulation: a framework for governance,,Businness and problem understanding; Planning and design,Beneficence; Beneficence; Governance,Responsibility; Social Good; Accountability; Sustainability; Well-being; Auditability,Does not apply,"4,1",Academic,Article; Theoretical Framework; Resource Compendium,Does not apply,https://doi.org/10.1007/s10676-021-09593-z,2021,"Patricia Gomes Rêgo de Almeida, Carlos Denner dos Santos, Josivania Silva Farias",https://www.researchgate.net/publication/351039094_Artificial_Intelligence_Regulation_a_framework_for_governance
331,DeepFault,DeepFault: Fault Localization for Deep Neural Networks,,Performance evaluation; Performance evaluation,Justice; Non-Maleficence,Auditability; Reliability; Safety,Computer Vision,"4,1",Academic,Code; Article,Python,https://doi.org/10.1007/978-3-030-16722-6_10,2019,"Hasan Ferit Eniser, Simos Gerasimou, Alper Sen","https://github.com/hfeniser/DeepFault

https://github.com/eth-sri/eran"
332,Managing Bias in Machine Learning Projects,Managing Bias in Machine Learning Projects,,"Businness and problem understanding; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Justice; Justice; Justice; Justice; Justice,Fairness,Does not apply,4,Academic,Article; Resource Compendium; Practical Framework,Does not apply,https://doi.org/10.1007/978-3-030-86797-3_7,2021,"Tobias Fahse, Viktoria Huber, Benjamin van Giffen",https://www.researchgate.net/publication/355346905_Managing_Bias_in_Machine_Learning_Projects
333,ECCOLA,ECCOLA - A method for implementing ethically aligned AI systems,,Businness and problem understanding; Planning and design; Planning and design; Planning and design; Planning and design,Beneficence; Non-Maleficence; Autonomy; Justice; Explicability,Social Good; Responsibility; Transparency; Accountability; Privacy; Safety; Quality Data; Reliability; Agency; Human Oversight; Sustainability; Auditability; Trade-offs; Prevention; Traceability; Explicability,Does not apply,"4,2",Academic,Article; Practical Framework; Guide,Does not apply,https://doi.org/10.1016/j.jss.2021.111067,2021,"Ville Vakkuri, Kai-Kristian Kemell, Marianna Jantunen, Erika Halme, Pekka Abrahamsson",https://figshare.com/articles/poster/Internet_resource_for_ECCOLA_-_a_Method_for_Implementing_Ethically_Aligned_AI_Systems/12136308
334,ML Ethics Tool,Designing Up with Value-Sensitive Design: Building a Field Guide for Ethical ML Development,,Businness and problem understanding; Planning and design,Non-Maleficence; Justice,Accountability; Privacy; Fairness,Does not apply,"4,4",Academic,Article; Guide; Tool Compendium; Resource Compendium; Website,Does not apply,https://doi.org/10.1145/3531146.3534626,2022,Karen Boyd,"http://karenboyd.org/DesigningUp.pdf

https://ml-ethics-tool.web.app/"
335,A Research Ethics Framework for the Clinical Translation of Healthcare Machine Learning,A Research Ethics Framework for the Clinical Translation of Healthcare Machine Learning,,Planning and design,Beneficence,Social Good; Responsibility; Trust,Does not apply,Does not apply,Academic,Article,Does not apply,https://doi.org/10.1080/15265161.2021.2013977,2022,"Melissa D. McCradden, James A. Anderson, Elizabeth A. Stephenson, Erik Drysdale, Lauren Erdman, Anna Goldenberg, Randi Zlotnik Shaul","https://www.nature.com/articles/s41591-020-1035-9

https://sci-hub.ru/10.1038/s41591-020-1035-9"
336,A Literature Review on Ethics for AI in Biomedical Research and Biobanking,A Literature Review on Ethics for AI in Biomedical Research and Biobanking,,Planning and design; Planning and design,Beneficence; Non-Maleficence,Responsibility; Safety; Transparency; Privacy,Does not apply,Does not apply,Academic,Article; Tool Compendium; Resource Compendium,Does not apply,https://doi.org/10.1055/s-0042-1742516,2022,"Michaela Kargl, Markus Plass, Heimo Müller",
337,The Canada Protocol: AI checklist for Mental Health & Suicide Prevention,Canada protocol: An ethical checklist for the use of artificial Intelligence in suicide prevention and mental health,,Businness and problem understanding; Planning and design; Businness and problem understanding,Beneficence; Non-Maleficence; Justice,Well-being; Security; Privacy; Transparency; Prevention; Fairness,Does not apply,Does not apply,Academic; Public,Article; Checklist,Does not apply,https://doi.org/10.1016/j.artmed.2020.101934,2020,"Carl-Maria Mörch, Abhishek Gupta, Brian L. Mishara","https://montrealethics.ai/the-canada-protocol-ai-checklist-for-mental-health-suicide-prevention/

https://montrealethics.ai/wp-content/uploads/2019/05/Canada-Protocol.pdf

https://sci-hub.ru/10.1016/j.artmed.2020.101934"
338,Interpretability versus Explainability: Classification for Understanding Deep Learning Systems and Models,Interpretability versus Explainability: Classification for Understanding Deep Learning Systems and Models,,Planning and design; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Does not apply,4,Academic,Article; Resource Compendium,Does not apply,https://doi.org/10.24423/cames.518,2022,"Ivars Namatēvs, Kaspars Sudars, Artis Dobrājs",
339,Aligning artificial intelligence with climate change mitigation,Aligning artificial intelligence with climate change mitigation,,Businness and problem understanding; Planning and design,Beneficence; Beneficence,Sustainability,Does not apply,"4,1",Academic,Article; Theoretical Framework,Does not apply,https://doi.org/10.1038/s41558-022-01377-7,2022,"Lynn H. Kaack, Priya L. Donti, Emma Strubell, George Kamiya, Felix Creutzig, David Rolnick",https://hal.science/hal-03368037/file/Kaack_2021_Aligning.pdf
340,Assessment of Ethics and Social Justice Aspects in Data Science and Artificial Intelligence,Assessment of Ethics and Social Justice Aspects in Data Science and Artificial Intelligence,,Businness and problem understanding; Planning and design; Performance evaluation,Beneficence; Non-Maleficence; Non-Maleficence,Social Good; Transparency; Accountability,Does not apply,4,Academic,Article; Tool Compendium,Does not apply,https://peer.asee.org/41550,2022,"Franz Kurfess, Katya Vasilaky, Tina Cheuk, Ryan Jenkins, Grace Nolan, Amir Hajrasouliha, Elise St. John","https://drive.google.com/drive/folders/1OORiDmcQ7ef7ROLZoqkMbJ5s8ByiYI--?usp=sharing

https://www.ethicscanvas.org/

https://ai4good.org/"
341,"Addressing Fairness, Bias, and Appropriate Use of Artificial Intelligence and Machine Learning in Global Health","Addressing Fairness, Bias, and Appropriate Use of Artificial Intelligence and Machine Learning in Global Health",,Planning and design,Justice,Fairness; Auditability,Does not apply,Does not apply,Academic,Article; Guide; Case Studies,Does not apply,https://doi.org/10.3389/frai.2020.561802,2021,"Richard Ribón Fletcher, Audace Nakeshimana,Olusubomi Olubeko",
342,DeepIV,Deep IV: A Flexible Approach for Counterfactual Prediction,,Model setup and training; Performance evaluation,Explicability; Explicability,Explicability; Interpretability,Multi-class Classification; Computer Vision,"4,1",Academic,Code; Article,Python,https://proceedings.mlr.press/v70/hartford17a.html,2017,"Jason Hartford, Greg Lewis, Kevin Leyton-Brown, Matt Taddy","https://github.com/jhartford/DeepIV

https://github.com/py-why/EconML/blob/main/notebooks/Deep%20IV%20Examples.ipynb"
343,Notions of explainability and evaluation approaches for explainable artificial intelligence,Notions of explainability and evaluation approaches for explainable artificial intelligence,,Planning and design,Explicability,Explicability; Interpretability,Does not apply,4,Academic,Article; Resource Compendium; Tool Compendium,Does not apply,https://doi.org/10.1016/j.inffus.2021.05.009,2021,"Giulia Vilone, Luca Longo",
344,The medical algorithmic audit,The medical algorithmic audit,,"Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Beneficence; Non-Maleficence; Justice; Explicability; Non-Maleficence,Well-being; Responsibility; Accountability; Transparency; Prevention; Reliability; Fairness; Auditability; Explicability,Does not apply,4,Academic,Article; Guide; Practical Framework,Does not apply,https://doi.org/10.1016/S2589-7500(22)00003-6,2022,"Xiaoxuan Liu, Ben Glocker, Melissa M. McCradden, Marzyeh Ghassemi, Alastair K. Denniston, Lauren Oakden-Rayner",
345,Aesthetic Faces Dataset,Who Loves Virtue as much as He Loves Beauty?: Deep Learning based Estimator for Aesthetics of Portraits,,"Collection, understanding and preparation of data",Justice,Fairness,Computer Vision,4,Academic,Article; Dataset; Code,Python,https://doi.org/10.5220/0009172905210528,2020,"Tobias Gerlach, Michael Danner, Le Ping Peng, Aidas Kaminickas, Wu Fei, Matthias Rätsch","https://www.researchgate.net/publication/340042101_Who_Loves_Virtue_as_much_as_He_Loves_Beauty_Deep_Learning_based_Estimator_for_Aesthetics_of_Portraits

https://github.com/markusoettinger/AestheticFacesToolbox"
346,Identifying Ethical Considerations for Machine Learning Healthcare Applications,Identifying Ethical Considerations for Machine Learning Healthcare Applications,,"Planning and design; Collection, understanding and preparation of data; Model setup and training; Performance evaluation; Deployment and monitoring",Beneficence; Non-Maleficence; Autonomy; Justice; Justice,Responsibility; Social Good; Transparency; Accountability; Prevention; Safety; Agency; Fairness; Auditability,Does not apply,4,Academic,Article; Theoretical Framework,Does not apply,https://doi.org/10.1080/15265161.2020.1819469,2020,"Danton S. Char, Michael D. Abràmoff, Chris Feudtner",https://www.bataafschgenootschap.nl/wp-content/uploads/2021/04/char-abramoff-ajob-2020-target.pdf
347,Auditing the AI Auditors: A Framework for Evaluating Fairness and Bias in High Stakes AI Predictive Models,Auditing the AI Auditors: A Framework for Evaluating Fairness and Bias in High Stakes AI Predictive Models,,"Collection, understanding and preparation of data; Model setup and training; Performance evaluation",Justice; Justice; Justice,Fairness; Auditability,Does not apply,4,Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1037/amp0000972,2022,"Richard N. Landers, Tara S. Behrend",
348,PPML-TSA,PPML-TSA: A modular privacy-preserving time series classification framework,,Model setup and training,Non-Maleficence,Privacy,Multi-class Classification; Time Series,"3,9",Academic,Article; Code,Python,https://doi.org/10.1016/j.simpa.2022.100286,2022,"Dominique Mercier, Adriano Lucieri, Mohsin Munir, Andreas Dengel, Sheraz Ahmed","https://github.com/DominiqueMercier/PPML-TSA

https://github.com/slzhang-git/L10-PPML-TSA"
349,TRIPOD-AI,Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence,,Deployment and monitoring,Non-Maleficence,Transparency; Accountability,Does not apply,Does not apply,Academic,Article; Practical Framework,Does not apply,https://doi.org/10.1136/bmjopen-2020-048008,2021,"Gary S. Collins, Paula Dhiman, Constanza L. Andaur Navarro, Jie Ma, Lotty Hooft, Johannes B. Reitsma, Patricia Logullo, Andrew L. Beam, Lily Peng, Ben Van Calster, Maarten van Smeden, Richard D. Riley, Karel GM. Moons",https://www.tripod-statement.org/
350,Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications,Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications,,Planning and design,Explicability,Explicability; Interpretability,Does not apply,4,Academic,Article; Resource Compendium; Tool Compendium,Does not apply,https://doi.org/10.1109/JPROC.2021.3060483,2021,"Wojciech Samek, Grégoire Montavon, Sebastian Lapuschkin, Christopher J. Anders, Klaus-Robert Müller",
351,MLInspect,MLINSPECT: A Data Distribution Debugger for Machine Learning Pipelines,,"Collection, understanding and preparation of data; Deployment and monitoring",Non-Maleficence; Justice,Reliability; Accountability; Fairness,Binary Classification; Multi-class Classification,"4,1",Academic,Code; Article,Python,https://doi.org/10.1145/3448016.3452759,2021,"Stefan Grafberger, Shubha Guha, Julia Stoyanovich, Sebastian Schelter",https://github.com/stefan-grafberger/mlinspect
352,AutoXAI,AutoXAI: A Framework to Automatically Select the Most Adapted XAI Solution,,Performance evaluation,Explicability,Explicability; Interpretability,Binary Classification; Regression,"4,1",Academic,Code; Article,Python,https://doi.org/10.1145/3511808.3557247,2022,"Robin Cugny, Julien Aligon, Max Chevalier, Geoffrey Roman Jimenez, Olivier Teste","https://arxiv.org/abs/2210.02795

https://github.com/robincugny/autoxai"